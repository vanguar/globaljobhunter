from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import random
import re
from typing import List, Dict, Optional

class FinalJoobleScaper:
    def __init__(self, headless: bool = False):
        """
        –§–∏–Ω–∞–ª—å–Ω—ã–π –≤–µ–±-—Å–∫—Ä–∞–ø–µ—Ä –¥–ª—è Jooble —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö
        """
        self.headless = headless
        self.driver = None
        self.wait = None
        
    def setup_driver(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ Chrome –¥—Ä–∞–π–≤–µ—Ä–∞"""
        print("üöÄ –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º Chrome –¥—Ä–∞–π–≤–µ—Ä...")
        
        chrome_options = Options()
        
        if self.headless:
            chrome_options.add_argument("--headless")
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ–±—Ö–æ–¥–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –±–æ—Ç–∞
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--window-size=1920,1080")
        chrome_options.add_argument("--disable-extensions")
        
        try:
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            self.wait = WebDriverWait(self.driver, 15)
            print("‚úÖ Chrome –¥—Ä–∞–π–≤–µ—Ä –≥–æ—Ç–æ–≤!")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –¥—Ä–∞–π–≤–µ—Ä–∞: {e}")
            raise
        
    def close_popups(self):
        """–£–ª—É—á—à–µ–Ω–Ω–æ–µ –∑–∞–∫—Ä—ã—Ç–∏–µ –≤—Å–ø–ª—ã–≤–∞—é—â–∏—Ö –æ–∫–æ–Ω"""
        print("üóÇÔ∏è –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–ø–ª—ã–≤–∞—é—â–∏–µ –æ–∫–Ω–∞...")
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –≤—Å–ø–ª—ã–≤–∞—é—â–∏–µ –æ–∫–Ω–∞
        close_selectors = [
            "[role='dialog'] button",
            "button[aria-label='Close']",
            ".modal-close",
            "button:contains('√ó')",
            "button:contains('Nein')"
        ]
        
        for selector in close_selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    if element.is_displayed() and element.is_enabled():
                        element.click()
                        time.sleep(1)
                        print(f"‚úÖ –ó–∞–∫—Ä—ã—Ç–æ –æ–∫–Ω–æ: {selector}")
            except:
                continue
        
        # –û—Å–æ–±—ã–µ —Å–ª—É—á–∞–∏ –¥–ª—è Jooble
        try:
            # –ö–Ω–æ–ø–∫–∞ "Nein" –¥–ª—è newsletter
            from selenium.webdriver.common.keys import Keys
            body = self.driver.find_element(By.TAG_NAME, "body")
            body.send_keys(Keys.ESCAPE)
            time.sleep(1)
            
            # –ü—Ä–∏–Ω–∏–º–∞–µ–º cookies
            cookie_buttons = self.driver.find_elements(By.XPATH, "//button[contains(text(), 'ALLE AKZEPTIEREN') or contains(text(), 'ALLE ABLEHNEN')]")
            for btn in cookie_buttons:
                if btn.is_displayed():
                    btn.click()
                    break
                    
        except:
            pass
            
        time.sleep(2)
    
    def search_jobs(self, keywords: str, location: str = "Deutschland", max_pages: int = 3) -> List[Dict]:
        """
        –ü–æ–∏—Å–∫ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ Jooble —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö
        """
        if not self.driver:
            self.setup_driver()
            
        jobs = []
        
        try:
            # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è –ø–æ–∏—Å–∫–∞
            search_keywords = keywords.replace(' ', '+').lower()
            search_url = f"https://de.jooble.org/stellenangebote-{search_keywords}"
            
            if location and location.lower() != "deutschland":
                search_url += f"?l={location.replace(' ', '+')}"
                
            print(f"üîç –ò—â–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏: {search_url}")
            
            for page in range(1, max_pages + 1):
                if page > 1:
                    page_url = search_url + ("&p=" if "?" in search_url else "?p=") + str(page)
                else:
                    page_url = search_url
                
                print(f"üìÑ –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—É {page}...")
                
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–æ–∏—Å–∫–∞
                self.driver.get(page_url)
                time.sleep(3)
                
                # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–ø–ª—ã–≤–∞—é—â–∏–µ –æ–∫–Ω–∞
                self.close_popups()
                time.sleep(2)
                
                # –ü–∞—Ä—Å–∏–º –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–∞ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ
                page_jobs = self._parse_jobs_detailed()
                jobs.extend(page_jobs)
                
                print(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(page_jobs)} –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page}")
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                time.sleep(random.uniform(3, 5))
                
                # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –º–∞–ª–æ –≤–∞–∫–∞–Ω—Å–∏–π, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
                if len(page_jobs) < 5:
                    print("üìÑ –ú–∞–ª–æ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ, –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ –∫–æ–Ω–µ—Ü")
                    break
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            
        return jobs
    
    def _parse_jobs_detailed(self) -> List[Dict]:
        """–î–µ—Ç–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö"""
        jobs = []
        
        try:
            print(f"üìÑ –ó–∞–≥–æ–ª–æ–≤–æ–∫: {self.driver.title}")
            
            # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –≤—Å–µ —Å—Ç–∞—Ç—å–∏/–∫–∞—Ä—Ç–æ—á–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–π
            job_containers = []
            
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π
            container_selectors = [
                "article",
                ".serp-item", 
                "[data-test*='vacancy']",
                "div[class*='job']",
                ".vacancy-serp__vacancy"
            ]
            
            for selector in container_selectors:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                if len(elements) >= 5:  # –ï—Å–ª–∏ –Ω–∞—à–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ
                    job_containers = elements
                    print(f"‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã: {selector} ({len(elements)} —à—Ç.)")
                    break
            
            if not job_containers:
                # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–æ–¥—Ö–æ–¥ - –∏—â–µ–º –ø–æ —Å—Å—ã–ª–∫–∞–º
                print("‚ö†Ô∏è –ö–æ–Ω—Ç–µ–π–Ω–µ—Ä—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –∏—â–µ–º –ø–æ —Å—Å—ã–ª–∫–∞–º...")
                return self._parse_by_links()
            
            # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—ã–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            for i, container in enumerate(job_containers[:25]):  # –ú–∞–∫—Å–∏–º—É–º 25 –≤–∞–∫–∞–Ω—Å–∏–π
                try:
                    job_data = self._extract_detailed_job_data(container, i + 1)
                    if job_data:
                        jobs.append(job_data)
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ {i+1}: {e}")
                    continue
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            
        return jobs
    
    def _parse_by_links(self) -> List[Dict]:
        """–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ —á–µ—Ä–µ–∑ —Å—Å—ã–ª–∫–∏"""
        jobs = []
        
        try:
            # –ò—â–µ–º –≤—Å–µ —Å—Å—ã–ª–∫–∏ –Ω–∞ –≤–∞–∫–∞–Ω—Å–∏–∏
            job_links = self.driver.find_elements(By.CSS_SELECTOR, "a[href*='/desc/']")
            print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Å—Å—ã–ª–æ–∫: {len(job_links)}")
            
            processed_links = set()
            
            for link in job_links[:30]:  # –ú–∞–∫—Å–∏–º—É–º 30 —Å—Å—ã–ª–æ–∫
                try:
                    href = link.get_attribute("href")
                    if href in processed_links:
                        continue
                    processed_links.add(href)
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å—Å—ã–ª–∫–∏ –∏ –µ—ë –æ–∫—Ä—É–∂–µ–Ω–∏—è
                    job_data = self._extract_from_link_context(link, len(jobs) + 1)
                    if job_data:
                        jobs.append(job_data)
                        
                except Exception as e:
                    continue
                    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –ø–æ —Å—Å—ã–ª–∫–∞–º: {e}")
            
        return jobs
    
    def _extract_detailed_job_data(self, container, index: int) -> Optional[Dict]:
        """–î–µ—Ç–∞–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ –≤–∞–∫–∞–Ω—Å–∏–∏"""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
            full_text = container.text.strip()
            lines = [line.strip() for line in full_text.split('\n') if line.strip()]
            
            # –ò—â–µ–º —Å—Å—ã–ª–∫—É –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title = f"Python Developer {index}"
            link = "–ù–µ—Ç —Å—Å—ã–ª–∫–∏"
            
            try:
                link_elem = container.find_element(By.CSS_SELECTOR, "a[href*='/desc/']")
                link = link_elem.get_attribute("href")
                
                # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —á–∞—Å—Ç–æ –≤ —Å—Å—ã–ª–∫–µ –∏–ª–∏ —Ä—è–¥–æ–º
                title_text = link_elem.text.strip()
                if title_text and len(title_text) > 5:
                    title = title_text
                else:
                    # –ò—â–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≤ —Ç–µ–≥–∞—Ö h1, h2, h3
                    for tag in ['h1', 'h2', 'h3']:
                        try:
                            h_elem = container.find_element(By.TAG_NAME, tag)
                            if h_elem.text.strip():
                                title = h_elem.text.strip()
                                break
                        except:
                            continue
            except:
                pass
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–º–ø–∞–Ω–∏—é, –ª–æ–∫–∞—Ü–∏—é, –∑–∞—Ä–ø–ª–∞—Ç—É –∏–∑ —Ç–µ–∫—Å—Ç–∞
            company = self._extract_company(lines, title)
            location = self._extract_location(lines)
            salary = self._extract_salary(lines)
            date = self._extract_date(lines)
            
            # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
            snippet = self._create_snippet(lines, title)
            
            return {
                "title": title,
                "company": company,
                "location": location,
                "salary": salary,
                "snippet": snippet,
                "link": link,
                "date": date,
                "source": "jooble"
            }
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è: {e}")
            return None
    
    def _extract_from_link_context(self, link_elem, index: int) -> Optional[Dict]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å—Å—ã–ª–∫–∏"""
        try:
            title = link_elem.text.strip()
            if not title or len(title) < 3:
                title = f"Python Developer {index}"
                
            href = link_elem.get_attribute("href")
            
            # –ò—â–µ–º —Ä–æ–¥–∏—Ç–µ–ª—å—Å–∫–∏–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
            try:
                # –ü–æ–¥–Ω–∏–º–∞–µ–º—Å—è –≤–≤–µ—Ä—Ö –ø–æ DOM –¥–æ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Å –¥–∞–Ω–Ω—ã–º–∏
                parent = link_elem
                for _ in range(3):  # –ú–∞–∫—Å–∏–º—É–º 3 —É—Ä–æ–≤–Ω—è –≤–≤–µ—Ä—Ö
                    parent = parent.find_element(By.XPATH, "..")
                    parent_text = parent.text.strip()
                    if len(parent_text) > len(title) + 50:  # –ï—Å–ª–∏ –≤ —Ä–æ–¥–∏—Ç–µ–ª–µ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö
                        break
                
                lines = [line.strip() for line in parent_text.split('\n') if line.strip()]
                
            except:
                lines = [title]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            company = self._extract_company(lines, title)
            location = self._extract_location(lines)
            salary = self._extract_salary(lines)
            date = self._extract_date(lines)
            snippet = self._create_snippet(lines, title)
            
            return {
                "title": title,
                "company": company,
                "location": location,
                "salary": salary,
                "snippet": snippet,
                "link": href,
                "date": date,
                "source": "jooble"
            }
            
        except Exception as e:
            return None
    
    def _extract_company(self, lines: List[str], title: str) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–∏"""
        for line in lines:
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
            if line == title or len(line) > 60:
                continue
                
            # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ–º –∫–æ–º–ø–∞–Ω–∏–∏
            if (len(line) > 2 and 
                'developer' not in line.lower() and 
                'python' not in line.lower() and
                'software' not in line.lower() and
                '‚Ç¨' not in line and
                'vor' not in line.lower() and
                'empfohlen' not in line.lower() and
                'vollzeit' not in line.lower()):
                
                # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                if len(line.split()) <= 4:
                    return line
        
        return "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
    
    def _extract_location(self, lines: List[str]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ª–æ–∫–∞—Ü–∏–∏"""
        # –ù–µ–º–µ—Ü–∫–∏–µ –≥–æ—Ä–æ–¥–∞
        german_cities = ['berlin', 'm√ºnchen', 'hamburg', 'k√∂ln', 'frankfurt', 'd√ºsseldorf', 
                        'stuttgart', 'dortmund', 'essen', 'leipzig', 'bremen', 'dresden',
                        'hannover', 'n√ºrnberg', 'duisburg', 'bochum', 'wuppertal', 'bielefeld']
        
        for line in lines:
            line_lower = line.lower()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≥–æ—Ä–æ–¥–æ–≤
            for city in german_cities:
                if city in line_lower:
                    return line
            
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ª–æ–∫–∞—Ü–∏–∏
            if any(keyword in line_lower for keyword in ['remote', 'homeoffice', 'deutschland', 'germany']):
                return line
                
        return "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
    
    def _extract_salary(self, lines: List[str]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞—Ä–ø–ª–∞—Ç—ã"""
        for line in lines:
            # –ò—â–µ–º —Å–∏–º–≤–æ–ª—ã –≤–∞–ª—é—Ç –∏ —á–∏—Å–ª–∞
            if re.search(r'[‚Ç¨$]\s*\d+|gehalt|\d+\s*[‚Ç¨$]|\d+\.\d+|\d+k', line.lower()):
                return line
                
        return "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
    
    def _extract_date(self, lines: List[str]) -> str:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞—Ç—ã –ø—É–±–ª–∏–∫–∞—Ü–∏–∏"""
        for line in lines:
            if any(keyword in line.lower() for keyword in ['vor', 'tag', 'woche', 'monat', 'heute', 'gestern']):
                if len(line) < 30:  # –ö–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ —Å –¥–∞—Ç–æ–π
                    return line
                    
        return "–ù–µ —É–∫–∞–∑–∞–Ω–∞"
    
    def _create_snippet(self, lines: List[str], title: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è"""
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫, –∏—Å–∫–ª—é—á–∞—è –∑–∞–≥–æ–ª–æ–≤–æ–∫
        snippet_lines = []
        for line in lines:
            if line != title and len(line) > 10:
                snippet_lines.append(line)
                if len(' '.join(snippet_lines)) > 150:
                    break
        
        snippet = ' '.join(snippet_lines)
        if len(snippet) > 200:
            snippet = snippet[:200] + "..."
            
        return snippet if snippet else "–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è"
    
    def close(self):
        """–ó–∞–∫—Ä—ã—Ç–∏–µ –±—Ä–∞—É–∑–µ—Ä–∞"""
        if self.driver:
            self.driver.quit()
            print("üîÑ –ë—Ä–∞—É–∑–µ—Ä –∑–∞–∫—Ä—ã—Ç")
            
    def __enter__(self):
        return self
        
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∫—Ä–∞–ø–µ—Ä–∞
if __name__ == "__main__":
    print("ü§ñ –¢–µ—Å—Ç–∏—Ä—É–µ–º –§–ò–ù–ê–õ–¨–ù–´–ô Jooble —Å–∫—Ä–∞–ø–µ—Ä...")
    
    with FinalJoobleScaper(headless=False) as scraper:
        jobs = scraper.search_jobs("Python Developer", "Berlin", max_pages=2)
        
        print(f"\nüìä –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(jobs)}")
        print("=" * 80)
        
        for i, job in enumerate(jobs[:10], 1):
            print(f"\n{i}. üéØ {job['title']}")
            print(f"   üè¢ –ö–æ–º–ø–∞–Ω–∏—è: {job['company']}")
            print(f"   üìç –õ–æ–∫–∞—Ü–∏—è: {job['location']}")
            print(f"   üí∞ –ó–∞—Ä–ø–ª–∞—Ç–∞: {job['salary']}")
            print(f"   üìÖ –î–∞—Ç–∞: {job['date']}")
            print(f"   üîó –°—Å—ã–ª–∫–∞: {job['link'][:80]}...")
            print(f"   üìù –û–ø–∏—Å–∞–Ω–∏–µ: {job['snippet'][:120]}...")
            print("-" * 80)