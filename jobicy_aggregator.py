#!/usr/bin/env python3
"""
Jobicy API Aggregator - –ë–µ—Å–ø–ª–∞—Ç–Ω—ã–µ —É–¥–∞–ª–µ–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏
–° —Å–æ–±–ª—é–¥–µ–Ω–∏–µ–º rate limits (1 –∑–∞–ø—Ä–æ—Å –≤ —á–∞—Å)
"""

import requests
import time
import json
import os
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from dataclasses import dataclass

@dataclass
class JobVacancy:
    id: str
    title: str
    company: str
    location: str
    salary: Optional[str]
    description: str
    apply_url: str
    source: str
    posted_date: str
    country: str
    job_type: Optional[str] = None
    language_requirement: str = "unknown"
    refugee_friendly: bool = False

class JobicyAggregator:
    def __init__(self):
        self.source_name = "Jobicy"
        self.base_url = "https://jobicy.com/api/v2/remote-jobs"
        self.cache_file = "shared_jobicy_cache.json"  # –û–±—â–∏–π –¥–ª—è –≤—Å–µ—Ö
        self.cache_duration_hours = 12  # –ö–µ—à–∏—Ä—É–µ–º –Ω–∞ 12 —á–∞—Å–æ–≤
        
    def search_jobs(self, preferences: Dict, progress_callback=None, cancel_check=None) -> List[JobVacancy]:
        """
        –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –∑–∞–ø—Ä–æ—Å –∫ Jobicy (–ø–æ—á–∏—Ç–∞–µ–º –∏–∑ –∫–µ—à–∞/—Å–æ—Ö—Ä–∞–Ω–∏–º), –ø–æ—Ç–æ–º
        —Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ–¥ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏.
        –î–æ–±–∞–≤–ª–µ–Ω—ã:
        - progress_callback(list[JobVacancy]) ‚Äî –æ—Ç–¥–∞—ë–º –ø–æ—Ä—Ü–∏—è–º–∏ –ø–æ –º–µ—Ä–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏,
        - cancel_check() ‚Äî –º—è–≥–∫–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞.
        """
        print(f"üîÑ {self.source_name}: –Ω–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ —É–¥–∞–ª—ë–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")

        selected_jobs = preferences.get('selected_jobs', [])
        it_jobs = [job for job in selected_jobs if self._is_it_related(job)]
        if not it_jobs:
            print(f"‚ÑπÔ∏è {self.source_name}: –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –Ω–µ –ø–æ–¥—Ö–æ–¥—è—Ç –¥–ª—è —É–¥–∞–ª—ë–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã")
            return []

        try:
            if cancel_check and cancel_check():
                return []

            # –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ –∫–µ—à)
            all_jobs = self._fetch_jobs_cached()
            # —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–¥–∞–≤–∞—Ç—å –±–∞—Ç—á–∏
            relevant_jobs = self._filter_relevant_jobs(all_jobs, it_jobs, progress_callback=progress_callback, cancel_check=cancel_check)
            print(f"‚úÖ {self.source_name}: –Ω–∞–π–¥–µ–Ω–æ {len(relevant_jobs)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
            return relevant_jobs

        except Exception as e:
            print(f"‚ùå {self.source_name} –æ—à–∏–±–∫–∞: {e}")
            return []

    
    def _is_it_related(self, job_name: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ–¥—Ö–æ–¥–∏—Ç –ª–∏ –ø—Ä–æ—Ñ–µ—Å—Å–∏—è –¥–ª—è —É–¥–∞–ª–µ–Ω–Ω–æ–π —Ä–∞–±–æ—Ç—ã"""
        remote_friendly_keywords = [
            # IT
            'python', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç', '—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', '–≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫', 
            '–¥–∞—Ç–∞-–∞–Ω–∞–ª–∏—Ç–∏–∫', '—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä', '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫',
            'it', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏',
            
            # –û—Ñ–∏—Å–Ω—ã–µ (–º–æ–≥—É—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–Ω—ã–º–∏)
            '–º–µ–Ω–µ–¥–∂–µ—Ä', '–º–∞—Ä–∫–µ—Ç–∏–Ω–≥', '–¥–∏–∑–∞–π–Ω', '–∫–æ–Ω—Ç–µ–Ω—Ç', '—Å–µ–æ',
            '–ø–µ—Ä–µ–≤–æ–¥—á–∏–∫', '–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä', '–∞–Ω–∞–ª–∏—Ç–∏–∫', '–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç',
            'hr', '—Ä–µ–∫—Ä—É—Ç–µ—Ä', '—Ñ–∏–Ω–∞–Ω—Å—ã', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '–ø–æ–¥–¥–µ—Ä–∂–∫–∞',
            '–ø—Ä–æ–¥–∞–∂–∏', '–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä', '–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç', '—Å–µ–∫—Ä–µ—Ç–∞—Ä—å',
            '–∂—É—Ä–Ω–∞–ª–∏—Å—Ç', '—Ä–µ–¥–∞–∫—Ç–æ—Ä', 'smm', 'pr', '—Ä–µ–∫–ª–∞–º–∞'
        ]
        return any(keyword in job_name.lower() for keyword in remote_friendly_keywords)
    
    def _fetch_jobs_cached(self) -> List[Dict]:
        """–û–î–ò–ù –∑–∞–ø—Ä–æ—Å —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º - —Å–æ–±–ª—é–¥–∞–µ–º rate limits"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        cached_data = self._load_cache()
        if cached_data:
            print(f"üéØ Jobicy: –∏—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ ({len(cached_data)} –≤–∞–∫–∞–Ω—Å–∏–π)")
            return cached_data
        
        # –ö–µ—à —É—Å—Ç–∞—Ä–µ–ª - –¥–µ–ª–∞–µ–º –û–î–ò–ù –∑–∞–ø—Ä–æ—Å
        print(f"üîç Jobicy: –∫–µ—à –ø—É—Å—Ç, –¥–µ–ª–∞–µ–º –ï–î–ò–ù–°–¢–í–ï–ù–ù–´–ô –∑–∞–ø—Ä–æ—Å –∫ API")
        print(f"‚è±Ô∏è Jobicy: —Å–æ–±–ª—é–¥–∞–µ–º rate limit - —Ç–æ–ª—å–∫–æ 1 –∑–∞–ø—Ä–æ—Å –Ω–∞ 2 —á–∞—Å–∞")
        
        try:
            response = requests.get(self.base_url, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                jobs = data.get('jobs', [])
                print(f"üü¢ Jobicy: –ø–æ–ª—É—á–µ–Ω–æ {len(jobs)} –≤–∞–∫–∞–Ω—Å–∏–π —Å API")
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫–µ—à
                self._save_cache(jobs)
                return jobs
            else:
                print(f"üî¥ Jobicy –æ—à–∏–±–∫–∞ {response.status_code}: {response.text}")
                return []
        except Exception as e:
            print(f"üî¥ Jobicy –æ—à–∏–±–∫–∞: {e}")
            return []
    
    def _load_cache(self) -> Optional[List[Dict]]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∫–µ—à–∞"""
        try:
            if not os.path.exists(self.cache_file):
                return None
                
            with open(self.cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ä–æ–∫ –¥–µ–π—Å—Ç–≤–∏—è –∫–µ—à–∞
            cache_time = datetime.fromisoformat(cache_data['timestamp'])
            if datetime.now() - cache_time < timedelta(hours=self.cache_duration_hours):
                return cache_data['jobs']
            else:
                print(f"‚è∞ Jobicy: –∫–µ—à —É—Å—Ç–∞—Ä–µ–ª ({cache_time})")
                return None
                
        except Exception as e:
            print(f"‚ö†Ô∏è Jobicy: –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–µ—à–∞: {e}")
            return None
    
    def _save_cache(self, jobs: List[Dict]):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∫–µ—à"""
        try:
            cache_data = {
                'timestamp': datetime.now().isoformat(),
                'jobs': jobs
            }
            with open(self.cache_file, 'w', encoding='utf-8') as f:
                json.dump(cache_data, f, ensure_ascii=False, indent=2)
            print(f"üíæ Jobicy: –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫–µ—à")
        except Exception as e:
            print(f"‚ö†Ô∏è Jobicy: –æ—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–µ—à–∞: {e}")
    
    def _filter_relevant_jobs(self, jobs_data: List[Dict], selected_jobs: List[str], progress_callback=None, cancel_check=None) -> List[JobVacancy]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º.
        –û—Ç–¥–∞—ë—Ç –±–∞—Ç—á–∏ (–ø–æ 5 —à—Ç—É–∫) —á–µ—Ä–µ–∑ progress_callback, —É–≤–∞–∂–∞–µ—Ç cancel_check().
        """
        relevant_jobs: List[JobVacancy] = []

        job_keywords = {
            '–¥–∞—Ç–∞-–∞–Ω–∞–ª–∏—Ç–∏–∫': ['data analyst', 'business analyst', 'analytics', 'bi analyst', 'reporting analyst', 'data scientist'],
            '—Å–∏—Å—Ç–µ–º–Ω—ã–π –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä': ['system administrator', 'sysadmin', 'system admin', 'infrastructure engineer', 'devops engineer', 'network admin', 'it admin', 'site reliability'],
            'python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫': ['python developer', 'python engineer', 'python programmer', 'django', 'flask'],
            '–≤–µ–±-—Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫': ['web developer', 'frontend developer', 'backend developer', 'fullstack developer', 'react', 'angular', 'vue'],
            '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç': ['software developer', 'software engineer', 'programmer', 'developer', 'engineer'],
            '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫': ['qa engineer', 'qa tester', 'test engineer', 'quality assurance', 'automation tester']
        }
        negative_keywords = [
            'sales', 'marketing', 'customer service', 'support representative',
            'account executive', 'business development', 'product manager',
            'program manager', 'project manager', 'marketing expert',
            'sales specialist', 'customer success', 'account manager',
            'technical product manager', 'solutions sales'
        ]

        # —Å–æ–±—Ä–∞—Ç—å –∫–ª—é—á–∏ –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π
        search_keywords = []
        for job in selected_jobs:
            job_lower = job.lower()
            found = False
            for key, keywords in job_keywords.items():
                if key in job_lower or job_lower in key:
                    search_keywords.extend(keywords)
                    found = True
                    break
            if not found:
                search_keywords.append(job_lower)

        print(f"üîç {self.source_name}: –∏—â–µ–º –ø–æ —Å–ª–æ–≤–∞–º: {search_keywords}")
        print(f"üö´ {self.source_name}: –∏—Å–∫–ª—é—á–∞–µ–º —Å–ª–æ–≤–∞: {negative_keywords}")

        batch: List[JobVacancy] = []
        for job_data in jobs_data:
            if cancel_check and cancel_check():
                # –æ—Ç–¥–∞–¥–∏–º –Ω–∞–∫–æ–ø–∏–≤—à–∏–π—Å—è –±–∞—Ç—á –ø–µ—Ä–µ–¥ –≤—ã—Ö–æ–¥–æ–º
                if progress_callback and batch:
                    try:
                        progress_callback(batch)
                    except Exception:
                        pass
                return relevant_jobs

            title = job_data.get('jobTitle', '').lower()
            description = job_data.get('jobExcerpt', '').lower()
            combined_text = f"{title} {description}"

            has_positive = any(keyword in combined_text for keyword in search_keywords)
            has_negative = any(negative in combined_text for negative in negative_keywords)

            if has_positive and not has_negative:
                job = self._normalize_job(job_data)
                if job:
                    relevant_jobs.append(job)
                    batch.append(job)
                    # –æ—Ç–¥–∞—ë–º –±–∞—Ç—á –∫–∞–∂–¥—ã–µ 5 –ø–æ–∑–∏—Ü–∏–π –¥–ª—è "–∂–∏–≤–æ–≥–æ" —Å—á—ë—Ç—á–∏–∫–∞
                    if progress_callback and len(batch) >= 5:
                        try:
                            progress_callback(batch)
                        except Exception:
                            pass
                        batch = []
            # –ø—Ä–∏ has_positive & has_negative ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º

        # –¥–æ–±—Ä–æ—Å–∏–º —Ö–≤–æ—Å—Ç –±–∞—Ç—á–∞
        if progress_callback and batch:
            try:
                progress_callback(batch)
            except Exception:
                pass

        return relevant_jobs

    
        
    def _normalize_job(self, raw_job: Dict) -> Optional[JobVacancy]:
        """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"""
        try:
            job_id = str(raw_job.get('id', ''))
            title = raw_job.get('jobTitle', 'No title')
            company = raw_job.get('companyName', 'No company')
            description = raw_job.get('jobExcerpt', 'No description')
            apply_url = raw_job.get('url', '')
            posted_date = raw_job.get('pubDate', 'Unknown')
            
            return JobVacancy(
                id=f"jobicy_{job_id}",
                title=title,
                company=company,
                location="Remote (–£–¥–∞–ª–µ–Ω–Ω–æ)",
                salary=None,
                description=description,
                apply_url=apply_url,
                source="Jobicy",
                posted_date=posted_date,
                country="Remote",
                job_type="Remote",
                language_requirement="unknown",
                refugee_friendly=False
            )
            
        except Exception as e:
            print(f"‚ùå Jobicy –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ—à–∏–±–∫–∞: {e}")
            return None