#!/usr/bin/env python3
"""
Remotive Aggregator for GlobalJobHunter v1.1
"""

import os
import requests
import time
from datetime import datetime
from typing import List, Dict, Optional
import hashlib

# --- –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ adzuna_aggregator ---
from adzuna_aggregator import JobVacancy, CacheManager, RateLimiter

# --- –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---
from base_aggregator import BaseJobAggregator

class RemotiveAggregator(BaseJobAggregator):
    """
    –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ Remotive API.
    - –£–ª—É—á—à–µ–Ω–æ: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω Rate Limiter.
    """
    def __init__(self, specific_jobs_map: Dict, cache_duration_hours: int = 12):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞.
        :param specific_jobs_map: –°–ª–æ–≤–∞—Ä—å –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ —Ä—É—Å—Å–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–π –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ.
        :param cache_duration_hours: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫–µ—à–∞ –≤ —á–∞—Å–∞—Ö.
        """
        super().__init__(source_name='Remotive')
        self.base_url = "https://remotive.com/api/remote-jobs"
        self.specific_jobs_map = specific_jobs_map
        self.cache_manager = CacheManager(cache_duration_hours=cache_duration_hours)
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ª–∏–º–∏—Ç –≤ 2 –∑–∞–ø—Ä–æ—Å–∞ –≤ –º–∏–Ω—É—Ç—É —Å–æ–≥–ª–∞—Å–Ω–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏
        self.rate_limiter = RateLimiter(requests_per_minute=2) 

        # –ö–∞—Ä—Ç–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –¥–ª—è Remotive API (–º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω—è—Ç—å)
        self.job_to_category_map = {
            'python developer': 'software-dev',
            'web developer': 'software-dev',
            'programmer': 'software-dev',
            'software developer': 'software-dev',
            'qa engineer': 'qa',
            'software tester': 'qa',
            'data analyst': 'data',
            'data scientist': 'data',
            'designer': 'design',
            'product manager': 'product',
            'manager': 'management',
            'sales assistant': 'sales-marketing',
            'marketer': 'sales-marketing',
            'recruiter': 'hr',
            'customer support': 'customer-service'
        }
        print(f"‚úÖ Remotive Aggregator v1.1 –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (Rate Limit: 2/min).")

    def get_supported_countries(self) -> Dict[str, Dict]:
        """Remotive - —ç—Ç–æ —Ç–æ–ª—å–∫–æ —É–¥–∞–ª–µ–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏, –ø–æ—ç—Ç–æ–º—É —Å–ø–∏—Å–æ–∫ —Å—Ç—Ä–∞–Ω –ø—É—Å—Ç."""
        return {}

    def search_jobs(self, preferences: Dict) -> List[JobVacancy]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞. –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –¥–ª—è –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏.
        """
        print(f"üì° {self.source_name}: –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π...")
        all_jobs: List[JobVacancy] = []
        
        selected_jobs = preferences.get('selected_jobs', [])

        if not selected_jobs:
            return []

        for russian_job_title in selected_jobs:
            english_keywords = self._get_english_keywords(russian_job_title)
            
            if not english_keywords:
                continue

            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –∫–ª—é—á–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
            primary_keyword = english_keywords[0]
            category = self.job_to_category_map.get(primary_keyword.lower())
            
            if category:
                print(f"    - –ò—â–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ '{category}' –¥–ª—è '{russian_job_title}'")
                jobs = self._fetch_jobs(params={'category': category})
                all_jobs.extend(jobs)
            else:
                # –ï—Å–ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ—Ç, –∏—â–µ–º –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                for keyword in english_keywords:
                    print(f"    - –ò—â–µ–º –ø–æ –∫–ª—é—á–µ–≤–æ–º—É —Å–ª–æ–≤—É: '{keyword}'")
                    jobs = self._fetch_jobs(params={'search': keyword})
                    all_jobs.extend(jobs)
        
        print(f"‚úÖ {self.source_name}: –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ –≤—Å–µ–≥–æ: {len(all_jobs)} –≤–∞–∫–∞–Ω—Å–∏–π.")
        return self._deduplicate_jobs(all_jobs)

    def _get_english_keywords(self, russian_job_title: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä—É—Å—Å–∫–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏."""
        for category in self.specific_jobs_map.values():
            if russian_job_title in category:
                return [term for term in category[russian_job_title][:3] if term]
        return []

    def _fetch_jobs(self, params: Dict) -> List[JobVacancy]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º."""
        cached_result = self.cache_manager.get_cached_result(params)
        if cached_result:
            return cached_result

        self.rate_limiter.wait_if_needed()
        
        try:
            response = requests.get(self.base_url, params=params, timeout=15)
            
            if response.status_code != 200:
                print(f"‚ùå {self.source_name} API –æ—à–∏–±–∫–∞ {response.status_code}: {response.text}")
                return []

            data = response.json()
            jobs_raw = data.get('jobs', [])
            
            search_term = params.get('search') or params.get('category')
            normalized_jobs = [
                job for job_data in jobs_raw 
                if (job := self._normalize_job_data(job_data, search_term)) is not None
            ]

            self.cache_manager.cache_result(params, normalized_jobs)
            print(f"    - –ù–∞–π–¥–µ–Ω–æ –∏ –∑–∞–∫–µ—à–∏—Ä–æ–≤–∞–Ω–æ: {len(normalized_jobs)} –≤–∞–∫–∞–Ω—Å–∏–π –¥–ª—è '{search_term}'.")
            return normalized_jobs

        except requests.Timeout:
            print(f"‚ö†Ô∏è {self.source_name}: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è '{params}'.")
            return []
        except Exception as e:
            print(f"‚ùå {self.source_name}: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
            return []

    def _normalize_job_data(self, raw_job: Dict, search_term: str) -> Optional[JobVacancy]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç API –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç JobVacancy.
        """
        try:
            title = raw_job.get('title', '')
            description = raw_job.get('description', '')
            
            url = raw_job.get('url')
            if not url:
                return None
            job_id = hashlib.md5(url.encode()).hexdigest()

            date_str = raw_job.get('publication_date', '')
            try:
                posted_date = datetime.fromisoformat(date_str.replace('Z', '+00:00')).strftime('%Y-%m-%d')
            except (ValueError, TypeError):
                posted_date = datetime.now().strftime('%Y-%m-%d')

            return JobVacancy(
                id=f"remotive_{job_id}",
                title=title,
                company=raw_job.get('company_name', 'Not specified'),
                location=raw_job.get('candidate_required_location', 'Worldwide'),
                salary=raw_job.get('salary'),
                description=description,
                apply_url=url,
                source=self.source_name,
                posted_date=posted_date,
                country='Remote',
                job_type=raw_job.get('job_type'),
                language_requirement=self.determine_language_requirement(title, description),
                refugee_friendly=self.is_refugee_friendly(title, description, search_term)
            )
        except Exception as e:
            print(f"‚ö†Ô∏è {self.source_name}: –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return None

    def is_relevant_job(self, job_title: str, job_description: str, search_term: str) -> bool:
        """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å."""
        # –î–ª—è –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–µ –Ω—É–∂–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞, —Ç.–∫. –æ–Ω–∏ —É–∂–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã
        if search_term in self.job_to_category_map.values():
             return True
        return search_term.lower() in job_title.lower()

    def _deduplicate_jobs(self, jobs: List[JobVacancy]) -> List[JobVacancy]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ URL –≤–∞–∫–∞–Ω—Å–∏–∏."""
        seen = set()
        unique_jobs = []
        for job in jobs:
            if job.apply_url not in seen:
                seen.add(job.apply_url)
                unique_jobs.append(job)
        return unique_jobs
