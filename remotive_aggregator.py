#!/usr/bin/env python3
"""
Remotive Aggregator for GlobalJobHunter v1.3
"""

import os
import requests
import time
from datetime import datetime
from typing import List, Dict, Optional
import hashlib
import re


# --- –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ adzuna_aggregator ---
from adzuna_aggregator import JobVacancy, CacheManager, RateLimiter

# --- –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---
from base_aggregator import BaseJobAggregator

try:
    from adzuna_aggregator import RateLimitedError, yield_briefly
except Exception:
    class RateLimitedError(Exception):
        pass
    import random, time
    def yield_briefly(base_ms: int = 200, jitter_ms: int = 120, cancel_check=None) -> bool:
        delay = (base_ms + (random.randint(0, jitter_ms) if jitter_ms > 0 else 0)) / 1000.0
        end = time.time() + delay
        while True:
            remain = end - time.time()
            if remain <= 0:
                break
            time.sleep(min(0.05, remain))
        return True


class RemotiveAggregator(BaseJobAggregator):
    """
    –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ Remotive API.
    - –£–õ–£–ß–®–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω —á–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å —É–¥–∞–ª–µ–Ω–Ω—ã–º–∏.
    - –ò–°–ü–†–ê–í–õ–ï–ù–û: –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –≤ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è Rate Limit.
    - –£–ª—É—á—à–µ–Ω–æ: –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–∏—Å–∫ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω Rate Limiter.
    """
    
    # --- –ù–û–í–û–ï: –°–ø–∏—Å–æ–∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∏—â–µ–º –Ω–∞ —ç—Ç–æ–º —Å–∞–π—Ç–µ ---
    NON_REMOTE_JOBS = {
        # –¢—Ä–∞–Ω—Å–ø–æ—Ä—Ç –∏ –¥–æ—Å—Ç–∞–≤–∫–∞
        '–í–æ–¥–∏—Ç–µ–ª—å —Ç–∞–∫—Å–∏', '–í–æ–¥–∏—Ç–µ–ª—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ B', '–í–æ–¥–∏—Ç–µ–ª—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ C',
        '–í–æ–¥–∏—Ç–µ–ª—å-–∫—É—Ä—å–µ—Ä', '–ö—É—Ä—å–µ—Ä –ø–µ—à–∫–æ–º', '–ö—É—Ä—å–µ—Ä-–¥–æ—Å—Ç–∞–≤—â–∏–∫ –µ–¥—ã',
        '–í–æ–¥–∏—Ç–µ–ª—å –∞–≤—Ç–æ–±—É—Å–∞', '–í–æ–¥–∏—Ç–µ–ª—å –≥—Ä—É–∑–æ–≤–∏–∫–∞',
        # –ê–≤—Ç–æ—Å–µ—Ä–≤–∏—Å
        '–ê–≤—Ç–æ–º–µ—Ö–∞–Ω–∏–∫', '–ê–≤—Ç–æ—Å–ª–µ—Å–∞—Ä—å', '–®–∏–Ω–æ–º–æ–Ω—Ç–∞–∂–Ω–∏–∫', '–î–∏–∞–≥–Ω–æ—Å—Ç',
        '–ú–∞—Å—Ç–µ—Ä-–ø—Ä–∏—ë–º—â–∏–∫', '–ö—É–∑–æ–≤—â–∏–∫', '–ú–∞–ª—è—Ä –ø–æ –∞–≤—Ç–æ',
        # –ê–ó–° –∏ –¢–æ–ø–ª–∏–≤–æ
        '–ó–∞–ø—Ä–∞–≤—â–∏–∫ –Ω–∞ –ê–ó–°', '–û–ø–µ—Ä–∞—Ç–æ—Ä –ê–ó–°', '–ö–∞—Å—Å–∏—Ä –Ω–∞ –ê–ó–°',
        # –ù–µ—Ñ—Ç—å –∏ –≥–∞–∑
        '–û–ø–µ—Ä–∞—Ç–æ—Ä –¥–æ–±—ã—á–∏', '–ü–æ–º–æ—â–Ω–∏–∫ –±—É—Ä–∏–ª—å—â–∏–∫–∞', '–†–∞–±–æ—á–∏–π –Ω–µ—Ñ—Ç–µ–±–∞–∑—ã',
        # –°—Ç—Ä–æ–∏—Ç–µ–ª—å—Å—Ç–≤–æ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ
        '–°—Ç—Ä–æ–∏—Ç–µ–ª—å-—Ä–∞–∑–Ω–æ—Ä–∞–±–æ—á–∏–π', '–ì—Ä—É–∑—á–∏–∫', '–°–∫–ª–∞–¥—Å–∫–æ–π —Ä–∞–±–æ—Ç–Ω–∏–∫',
        '–†–∞–∑–Ω–æ—Ä–∞–±–æ—á–∏–π', '–†–∞–±–æ—á–∏–π –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ',
        # –û–±—â–µ–ø–∏—Ç –∏ —Å–µ—Ä–≤–∏—Å
        '–û—Ñ–∏—Ü–∏–∞–Ω—Ç', '–ë–∞—Ä–º–µ–Ω', '–ü–æ–≤–∞—Ä', '–ü–æ–º–æ—â–Ω–∏–∫ –ø–æ–≤–∞—Ä–∞', '–ü–æ—Å—É–¥–æ–º–æ–π—â–∏–∫',
        '–ö–∞—Å—Å–∏—Ä', '–ü—Ä–æ–¥–∞–≤–µ—Ü',
        # –°–µ—Ä–≤–∏—Å –∏ –æ–±—Å–ª—É–∂–∏–≤–∞–Ω–∏–µ
        '–£–±–æ—Ä—â–∏–∫', '–°–∞–¥–æ–≤–Ω–∏–∫', '–î–æ–º—Ä–∞–±–æ—Ç–Ω–∏—Ü–∞', '–ú–∞—Å—Å–∞–∂–∏—Å—Ç',
        # –£—Ö–æ–¥ –∏ –º–µ–¥–∏—Ü–∏–Ω–∞ (—Ç—Ä–µ–±—É—é—â–∏–µ —Ñ–∏–∑–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è)
        '–ú–µ–¥—Å–µ—Å—Ç—Ä–∞', '–°–∏–¥–µ–ª–∫–∞', '–ù—è–Ω—è', '–ì—É–≤–µ—Ä–Ω–∞–Ω—Ç–∫–∞', '–£—Ö–æ–¥ –∑–∞ –ø–µ–Ω—Å–∏–æ–Ω–µ—Ä–∞–º–∏'
    }
    
    def _get_english_keywords(self, text: str) -> str:
        """
        Back-compat: —Ä–∞–Ω—å—à–µ –≤—ã–∑—ã–≤–∞–ª—Å—è —ç—Ç–æ—Ç –ø—Ä–∏–≤–∞—Ç–Ω—ã–π –º–µ—Ç–æ–¥.
        –°–µ–π—á–∞—Å –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º text –∫–∞–∫ –µ—Å—Ç—å (–∏–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º, –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–µ–ª–ø–µ—Ä).
        """
        # –ï—Å–ª–∏ –µ—Å—Ç—å —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ç–æ—Ä ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ:
        # return self._normalize_keywords(text)
        return text

    # 2) –ó–∞–ø—Ä–æ—Å –≤ Remotive: –±–µ–∑–æ–ø–∞—Å–Ω—ã–π –±–∞—Ç—á–∏–Ω–≥ + –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–Ω—É–¥–∏—Ç—å —Å–≤–µ–∂–∏–π –∑–∞–ø—Ä–æ—Å
    def _query_remotive(self, terms_or_params, progress_callback=None, cancel_check=None, fresh: bool = False) -> List[JobVacancy]:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –æ–±—ë—Ä—Ç–∫–∞:
        ‚Ä¢ dict —Å {'category': slug} ‚Üí –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏.
        ‚Ä¢ list/tuple/str ‚Üí –∑–∞–ø—Ä–æ—Å(—ã) –ø–æ search —Å –±–∞—Ç—á–∏–Ω–≥–æ–º 3‚Äì4 —Ç–µ—Ä–º–∏–Ω–∞ / <=80 —Å–∏–º–≤–æ–ª–æ–≤.
        –í–Ω—É—Ç—Ä–∏ –∑–æ–≤—ë–º _fetch_jobs(..., max_retries=2).
        """
        def _run_one(params: Dict) -> List[JobVacancy]:
            jobs = self._fetch_jobs(params, fresh=fresh, max_retries=2)
            if jobs and progress_callback:
                try:
                    progress_callback(list(jobs))
                except Exception:
                    pass
            return jobs or []

        # –í–µ—Ç–∫–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        if isinstance(terms_or_params, dict) and terms_or_params.get("category"):
            return _run_one({"category": terms_or_params["category"]})

        # –í–µ—Ç–∫–∞ search
        if isinstance(terms_or_params, (list, tuple)):
            cleaned = [str(t).strip() for t in terms_or_params if str(t).strip()]
        else:
            cleaned = [str(terms_or_params or "").strip()] if str(terms_or_params or "").strip() else []

        if not cleaned:
            return []

        results: List[JobVacancy] = []
        batch: List[str] = []
        curr_len = 0
        MAX_TERMS = 4
        MAX_LEN = 80

        for t in cleaned:
            add_len = (1 if batch else 0) + len(t)
            if len(batch) >= MAX_TERMS or (curr_len + add_len) > MAX_LEN:
                results.extend(_run_one({'search': " ".join(batch)}))
                batch, curr_len = [t], len(t)
            else:
                batch.append(t)
                curr_len += add_len

        if batch:
            results.extend(_run_one({'search': " ".join(batch)}))

        return results

    
    def __init__(self, specific_jobs_map: Dict, cache_duration_hours: Optional[int] = None):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Remotive.
        TTL: REMOTIVE_CACHE_HOURS > CACHE_TTL_HOURS > 24 (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é).
        """
        super().__init__(source_name='Remotive')
        self.cooldown_until = 0
        self.base_url = "https://remotive.com/api/remote-jobs"
        self.specific_jobs_map = specific_jobs_map

        # TTL –∫–µ—à–∞ (—á–∞—Å—ã)
        if cache_duration_hours is None:
            try:
                cache_duration_hours = int(os.getenv('REMOTIVE_CACHE_HOURS', os.getenv('CACHE_TTL_HOURS', '24')))
            except Exception:
                cache_duration_hours = 24

        self.cache_manager = CacheManager(cache_duration_hours=cache_duration_hours)
        self.rate_limiter = RateLimiter(requests_per_minute=2)

        # –ú–∞–ø–ø–∏–Ω–≥ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –∫–ª—é—á–µ–π ‚Üí –∫–∞—Ç–µ–≥–æ—Ä–∏–π Remotive
        self.job_to_category_map = {
            'python developer': 'software-dev',
            'web developer': 'software-dev',
            'programmer': 'software-dev',
            'software developer': 'software-dev',
            'qa engineer': 'qa',
            'software tester': 'qa',
            'data analyst': 'data',
            'data scientist': 'data',
            'designer': 'design',
            'product manager': 'product',
            'manager': 'management',
            'sales assistant': 'sales-marketing',
            'marketer': 'sales-marketing',
            'recruiter': 'hr',
            'customer support': 'customer-service'
        }

        print(f"‚úÖ Remotive Aggregator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (TTL={cache_duration_hours}—á, RL=2/min).")

    def _guess_category_slug(self, ru_titles: List[str]) -> Optional[str]:
        """
        –ü—Ä–æ–±—É–µ–º —É–≥–∞–¥–∞—Ç—å slug –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ Remotive –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º RU-–ø—Ä–æ—Ñ–µ—Å—Å–∏—è–º.
        –ï—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω—ã ‚Äî –≤–µ—Ä–Ω—ë–º None (—Ç–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º search).
        """
        text = " ".join(ru_titles).lower()

        # –±–∞–∑–æ–≤—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è (–º–æ–∂–µ—à—å –¥–æ–ø–æ–ª–Ω—è—Ç—å –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏)
        m = {
            "software-dev":  ["—Ä–∞–∑—Ä–∞–±–æ—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç", "developer", "–∏–Ω–∂–µ–Ω–µ—Ä –ø–æ –ü–û", "qa", "—Ç–µ—Å—Ç–∏—Ä–æ–≤"],
            "data":          ["–∞–Ω–∞–ª–∏—Ç–∏–∫", "data", "–¥–∞–Ω–Ω", "scientist"],
            "design":        ["–¥–∏–∑–∞–π–Ω", "ui", "ux", "product designer"],
            "product":       ["–ø—Ä–æ–¥–∞–∫—Ç", "product manager", "–ø—Ä–æ–¥—É–∫—Ç"],
            "management":    ["–º–µ–Ω–µ–¥–∂–µ—Ä", "—Ä—É–∫–æ–≤–æ–¥", "project", "team lead", "–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä", "–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä"],
            "sales-marketing":["–º–∞—Ä–∫–µ—Ç", "smm", "seo", "–∫–æ–Ω—Ç–µ–Ω—Ç", "–ø—Ä–æ–¥–∞–∂", "sales", "marketing"],
            "hr":            ["hr", "—Ä–µ–∫—Ä—É—Ç–µ—Ä", "–∫–∞–¥—Ä–æ–≤", "talent"],
            "customer-service":["–ø–æ–¥–¥–µ—Ä–∂–∫", "—Å–∞–ø–ø–æ—Ä—Ç", "support", "customer"],
            "devops":        ["devops", "sre", "–∞–¥–º–∏–Ω", "–∏–Ω—Ñ—Ä–∞"],
            "finance-legal": ["–±—É—Ö–≥–∞–ª—Ç", "—Ñ–∏–Ω–∞–Ω—Å", "—é—Ä–∏—Å—Ç", "legal"],
            "writing":       ["–∫–æ–ø–∏—Ä–∞–π—Ç", "writer", "—Ä–µ–¥–∞–∫—Ç–æ—Ä", "–∫–æ–Ω—Ç–µ–Ω—Ç–º–µ–π–∫–µ—Ä"],
            "education":     ["—É—á–∏—Ç–µ–ª", "–ø—Ä–µ–ø–æ–¥–∞–≤", "education", "coach", "—Ç—Ä–µ–Ω–µ—Ä"],
            "sales":         ["sales", "–∞–∫–∫–∞—É–Ω—Ç", "account"],
        }

        for slug, cues in m.items():
            if any(cue in text for cue in cues):
                return slug

        return None
        


    def get_supported_countries(self) -> Dict[str, Dict]:
        return {}

    def search_jobs(self, preferences: Dict, progress_callback=None, cancel_check=None) -> List[JobVacancy]:
        """
        –°—Ç—Ä–∞—Ç–µ–≥–∏—è (–ø–æ –¥–æ–∫–µ Remotive):
        1) –ï—Å–ª–∏ –º–æ–∂–µ–º —É–≥–∞–¥–∞—Ç—å slug –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ ‚Äî —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º ?category=slug.
        2) –ï—Å–ª–∏ –º–∞–ª–æ/–ø—É—Å—Ç–æ ‚Äî fallback –Ω–∞ ?search=... (EN-–∫–ª—é—á–∏).
        3) –ù–µ–ø—É—Å—Ç–æ–π –∫–µ—à —É–≤–∞–∂–∞–µ–º; –ø—É—Å—Ç–æ–π –Ω–µ —Ü–µ–º–µ–Ω—Ç–∏—Ä—É–µ–º. –ï—Å—Ç—å —Ä–µ—Ç—Ä–∞–∏.
        """
        all_jobs: List[JobVacancy] = []

        selected = preferences.get('selected_jobs') or []
        if not selected:
            return []

        # –ú–Ø–ì–ö–ê–Ø —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –æ—Ñ–ª–∞–π–Ω‚Äë—Ä–æ–ª–µ–π (–Ω–µ –æ–±–Ω—É–ª—è–µ–º —Å–æ–≤—Å–µ–º)
        initial_count = len(selected)
        filtered = [j for j in selected if j not in self.NON_REMOTE_JOBS]
        if not filtered:
            print(f"‚ÑπÔ∏è Remotive: –≤—Å–µ {initial_count} –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–æ—Ñ–µ—Å—Å–∏–π –ø–æ–º–µ—á–µ–Ω—ã –∫–∞–∫ –æ—Ñ–ª–∞–π–Ω ‚Äî –≤—Å—ë –∂–µ –ø—Ä–æ–±—É–µ–º –ø–æ –Ω–∏–º (fallback).")
            filtered = selected
        else:
            dropped = set(selected) - set(filtered)
            if dropped:
                print(f"‚ÑπÔ∏è Remotive: –∏—Å–∫–ª—é—á–∏–ª –æ—Ñ–ª–∞–π–Ω‚Äë—Å–ø–∏—Å–∫–∏: {', '.join(dropped)}")
        selected = filtered

        try:
            # 1) –ü–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏—é (slug) ‚Äî –û–î–ò–ù –∑–∞–ø—Ä–æ—Å –¥–∞—ë—Ç –º–Ω–æ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ
            slug = self._guess_category_slug(selected)
            cat_jobs: List[JobVacancy] = []
            if slug:
                cat_jobs = self._query_remotive({"category": slug}, progress_callback=progress_callback, cancel_check=cancel_check)
                # _query_remotive –ø–æ–Ω–∏–º–∞–µ—Ç –∏ dict params (category), –∏ list/str terms

            # 2) –ï—Å–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø—É—Å—Ç–æ/–º–∞–ª–æ ‚Äî –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –ø—Ä–æ–±—É–µ–º —Ç–æ—á–µ—á–Ω—ã–µ search‚Äë–∑–∞–ø—Ä–æ—Å—ã
            if cancel_check and cancel_check():
                return self._deduplicate_jobs(cat_jobs)

            search_jobs_total: List[JobVacancy] = []
            if len(cat_jobs) < 10:  # –ø–æ—Ä–æ–≥ –º–æ–∂–Ω–æ –ø–æ–¥–≤–∏–Ω—É—Ç—å
                for ru_title in selected:
                    if cancel_check and cancel_check():
                        break
                    terms = self._get_english_keywords(ru_title)
                    if not terms:
                        continue
                    # –∞–∫–∫—É—Ä–∞—Ç–Ω—ã–π –±–∞—Ç—á–∏–Ω–≥ –∏ —Ä–µ—Ç—Ä–∞–∏ ‚Äî –≤–Ω—É—Ç—Ä–∏ _query_remotive
                    search_jobs_total.extend(
                        self._query_remotive(terms, progress_callback=progress_callback, cancel_check=cancel_check)
                    )

            all_jobs.extend(cat_jobs)
            all_jobs.extend(search_jobs_total)

        except RateLimitedError:
            print(f"‚õî {self.source_name}: –∏—Å—Ç–æ—á–Ω–∏–∫ –ø–µ—Ä–µ–≤–µ–¥—ë–Ω –≤ cooldown (429).")
        except Exception as e:
            print(f"‚ùå {self.source_name}: –æ—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ ‚Äî {e}")

        deduped = self._deduplicate_jobs(all_jobs)
        print(f"‚úÖ {self.source_name}: –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ –≤—Å–µ–≥–æ: {len(deduped)} –≤–∞–∫–∞–Ω—Å–∏–π.")
        return deduped

    # 3) –ö–µ—à: —É–≤–∞–∂–∞–µ–º –Ω–µ–ø—É—Å—Ç–æ–π –∫–µ—à; –ø—É—Å—Ç–æ–π –∫–µ—à –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏ –Ω–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º
    def _fetch_jobs(self, params: Dict, fresh: bool = False, max_retries: int = 2) -> List[JobVacancy]:
        """
        –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∫ Remotive (—Å –∫–µ—à–µ–º + –ø–æ–≤—Ç–æ—Ä—ã).
        –ö–µ—à:
        ‚Ä¢ fresh=True ‚Üí –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —á—Ç–µ–Ω–∏–µ –∫–µ—à–∞ (–Ω–æ –ø–∏—Å–∞—Ç—å –º–æ–∂–Ω–æ).
        ‚Ä¢ –Ω–µ–ø—É—Å—Ç–æ–π –∫–µ—à ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ–º.
        ‚Ä¢ –ø—É—Å—Ç–æ–π –∫–µ—à ‚Üí –ù–ï –≤–æ–∑–≤—Ä–∞—â–∞–µ–º, –∏–¥—ë–º –≤ API.
        ‚Ä¢ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –∏–∑ API –ù–ï –∫–µ—à–∏—Ä—É–µ–º.
        –ü–æ–≤—Ç–æ—Ä—ã:
        ‚Ä¢ —Ç–∞–π–º–∞—É—Ç/—Å–µ—Ç–µ–≤–∞—è/5xx ‚Üí retry —Å –ª—ë–≥–∫–∏–º –¥–∂–∏—Ç—Ç–µ—Ä–æ–º.
        ‚Ä¢ 429 ‚Üí cooldown –∏ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ.
        """
        now = time.time()
        if getattr(self, "cooldown_until", 0) > now:
            left = int(self.cooldown_until - now)
            print(f"‚õî {self.source_name}: cooldown –µ—â—ë {left}s ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º {params}.")
            raise RateLimitedError("REMOTIVE_COOLDOWN")

        tag = params.get('search') or params.get('category')

        if not fresh:
            cached = self.cache_manager.get_cached_result(params)
            if cached is not None:
                if cached:
                    print(f"    üíæ Cache HIT Remotive –¥–ª—è '{tag}': {len(cached)}")
                    return cached
                else:
                    print(f"    üíæ Cache HIT Remotive (empty) –¥–ª—è '{tag}', –ø—Ä–æ–±—É–µ–º API...")

        attempts = 1 + max(0, int(max_retries))
        last_err = None

        for attempt in range(1, attempts + 1):
            self.rate_limiter.wait_if_needed()
            try:
                r = requests.get(self.base_url, params=params, timeout=12)
                if r.status_code == 200:
                    data = r.json() or {}
                    jobs_raw = data.get('jobs') or []
                    out: List[JobVacancy] = []
                    for raw in jobs_raw:
                        j = self._normalize_job_data(raw, tag or "")
                        if j:
                            out.append(j)

                    if out:
                        self.cache_manager.cache_result(params, out)
                        print(f"    üåê Remotive '{tag}': +{len(out)} (cached)")
                    else:
                        print(f"    üåê Remotive '{tag}': +0 (not cached)")
                    return out

                if r.status_code == 429:
                    cooldown = int(os.getenv("REMOTIVE_COOLDOWN_SEC", "120"))
                    self.cooldown_until = time.time() + cooldown
                    print(f"‚õî Remotive 429 ‚Üí cooldown {cooldown}s –¥–ª—è '{tag}'")
                    raise RateLimitedError("REMOTIVE_RATE_LIMIT")

                if 500 <= r.status_code <= 599:
                    last_err = RuntimeError(f"HTTP {r.status_code}")
                    print(f"‚ö†Ô∏è {self.source_name}: HTTP {r.status_code} –¥–ª—è '{tag}', –ø–æ–ø—ã—Ç–∫–∞ {attempt}/{attempts}")
                    if attempt < attempts:
                        yield_briefly(300, 300)
                        continue
                    return []

                print(f"‚ùå {self.source_name} HTTP {r.status_code}: {r.text[:200]}")
                return []

            except requests.Timeout as e:
                last_err = e
                print(f"‚ö†Ô∏è {self.source_name}: —Ç–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è '{tag}', –ø–æ–ø—ã—Ç–∫–∞ {attempt}/{attempts}")
                if attempt < attempts:
                    yield_briefly(300, 300)
                    continue
                return []
            except requests.RequestException as e:
                last_err = e
                print(f"‚ö†Ô∏è {self.source_name}: —Å–µ—Ç–µ–≤–∞—è –æ—à–∏–±–∫–∞ –¥–ª—è '{tag}': {e}, –ø–æ–ø—ã—Ç–∫–∞ {attempt}/{attempts}")
                if attempt < attempts:
                    yield_briefly(300, 300)
                    continue
                return []
            except RateLimitedError:
                raise
            except Exception as e:
                last_err = e
                print(f"‚ùå {self.source_name}: –æ—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ '{tag}': {e}")
                return []

        if last_err:
            print(f"‚ùå {self.source_name}: –∏—Å—á–µ—Ä–ø–∞–Ω—ã –ø–æ–ø—ã—Ç–∫–∏ –¥–ª—è '{tag}': {last_err}")
        return []



    def _normalize_job_data(self, raw_job: Dict, search_term: str) -> Optional[JobVacancy]:
        try:
            title = raw_job.get('title', '')
            description = raw_job.get('description', '')
            
            url = raw_job.get('url')
            if not url:
                return None
            job_id = hashlib.md5(url.encode()).hexdigest()

            date_str = raw_job.get('publication_date', '')
            try:
                posted_date = datetime.fromisoformat(date_str.replace('Z', '+00:00')).strftime('%Y-%m-%d')
            except (ValueError, TypeError):
                posted_date = datetime.now().strftime('%Y-%m-%d')

            return JobVacancy(
                id=f"remotive_{job_id}",
                title=title,
                company=raw_job.get('company_name', 'Not specified'),
                location=raw_job.get('candidate_required_location', 'Worldwide'),
                salary=raw_job.get('salary'),
                description=description,
                apply_url=url,
                source=self.source_name,
                posted_date=posted_date,
                country='Remote',
                job_type=raw_job.get('job_type'),
                language_requirement=self.determine_language_requirement(title, description),
                refugee_friendly=self.is_refugee_friendly(title, description, search_term)
            )
        except Exception as e:
            print(f"‚ö†Ô∏è {self.source_name}: –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return None

    def is_relevant_job(self, job_title: str, job_description: str, search_term: str) -> bool:
        """–ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å."""
        if search_term in self.job_to_category_map.values():
             return True
        
        search_keywords = search_term.lower().split()
        title_lower = job_title.lower()
        return any(keyword in title_lower for keyword in search_keywords)

    def _deduplicate_jobs(self, jobs: List[JobVacancy]) -> List[JobVacancy]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ URL –≤–∞–∫–∞–Ω—Å–∏–∏."""
        seen = set()
        unique_jobs = []
        for job in jobs:
            if job.apply_url not in seen:
                seen.add(job.apply_url)
                unique_jobs.append(job)
        return unique_jobs