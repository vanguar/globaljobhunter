#!/usr/bin/env python3
"""
Careerjet Aggregator for GlobalJobHunter
"""

import os
import requests
import time
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import asdict
import hashlib
from dotenv import load_dotenv

# --- –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ adzuna_aggregator ---
from adzuna_aggregator import JobVacancy, CacheManager, RateLimiter, GlobalJobAggregator

# --- –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---
from base_aggregator import BaseJobAggregator

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

class CareerjetAggregator(BaseJobAggregator):
    """
    –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ Careerjet API.
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–æ–∏—Å–∫ –∫–∞–∫ –ø–æ —Å—Ç—Ä–∞–Ω–µ, —Ç–∞–∫ –∏ –ø–æ –≥–æ—Ä–æ–¥—É.
    - **–ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞:** –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.
    """
    def __init__(self, adzuna_countries: Dict, specific_jobs_map: Dict, cache_duration_hours: int = 12):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞.
        """
        super().__init__(source_name='Careerjet')
        self.base_url = "http://public.api.careerjet.net/search"
        
        self.affid = os.getenv('CAREERJET_AFFID')
        if not self.affid:
            raise ValueError("CAREERJET_AFFID –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")

        self.cache_manager = CacheManager(cache_duration_hours=cache_duration_hours)
        self.rate_limiter = RateLimiter(requests_per_minute=25)
        
        self.country_map = {
            'gb': 'United Kingdom', 'us': 'United States', 'de': 'Germany',
            'fr': 'France', 'es': 'Spain', 'it': 'Italy', 'nl': 'Netherlands',
            'pl': 'Poland', 'ca': 'Canada', 'au': 'Australia', 'at': 'Austria',
            'ch': 'Switzerland', 'be': 'Belgium', 'se': 'Sweden', 'no': 'Norway',
            'dk': 'Denmark', 'cz': 'Czech Republic', 'sk': 'Slovakia'
        }

        self.adzuna_countries = adzuna_countries
        self.specific_jobs_map = specific_jobs_map

        print(f"‚úÖ Careerjet Aggregator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (affid: ...{self.affid[-4:]})")

    def get_supported_countries(self) -> Dict[str, Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–∞–Ω, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —ç—Ç–∏–º –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–æ–º."""
        return {}

    def search_jobs(self, preferences: Dict, progress_callback=None, cancel_check=None) -> List[JobVacancy]:
        """–ò—â–µ–º –ø–æ –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏/—Å—Ç—Ä–∞–Ω–µ/–≥–æ—Ä–æ–¥—É. –ü—Ä–æ–≥—Ä–µ—Å—Å –∏ –æ—Ç–º–µ–Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è."""
        print(f"üì° {self.source_name}: –Ω–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫...")
        all_jobs: List[JobVacancy] = []

        selected_jobs = preferences.get('selected_jobs', [])
        countries = preferences.get('countries', [])
        cities = preferences.get('cities', [])

        if not selected_jobs or not countries:
            return []

        for russian_job_title in selected_jobs:
            english_keywords = self._get_english_keywords(russian_job_title)
            if not english_keywords:
                print(f"‚ö†Ô∏è {self.source_name}: –Ω–µ—Ç —Å–ª–æ–≤–∞—Ä—è –¥–ª—è '{russian_job_title}', –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            keywords = " ".join(sorted(set(english_keywords)))
            print(f"‚ÑπÔ∏è {self.source_name}: '{russian_job_title}' ‚Üí '{keywords}'")

            for country_code in countries:
                country_name_for_api = self.country_map.get(country_code)
                if not country_name_for_api:
                    continue

                if cities:
                    for city in cities:
                        search_location = f"{city}, {country_name_for_api}"
                        jobs = self._fetch_all_pages(keywords, search_location, country_code, progress_callback=progress_callback, cancel_check=cancel_check)
                        if jobs:
                            all_jobs.extend(jobs)
                else:
                    search_location = country_name_for_api
                    jobs = self._fetch_all_pages(keywords, search_location, country_code, progress_callback=progress_callback, cancel_check=cancel_check)
                    if jobs:
                        all_jobs.extend(jobs)

        print(f"‚úÖ {self.source_name}: –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ–≥–æ: {len(all_jobs)}")
        return self._deduplicate_jobs(all_jobs)



    def _fetch_all_pages(self, keywords: str, location: str, country_code: str, progress_callback=None, cancel_check=None) -> List[JobVacancy]:
        """–ü–æ–ª—É—á–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏, –æ—Ç–¥–∞–≤–∞—è –ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ—Ä—Ü–∏—è–º–∏."""
        page = 1
        total_jobs: List[JobVacancy] = []

        while True:
            if cancel_check and cancel_check():
                break

            search_params = {
                'affid': self.affid,
                'keywords': keywords,
                'location': location,
                'page': page,
                'sort': 'date',
                'user_ip': '127.0.0.1',
            }

            try:
                response = requests.get(self.base_url, params=search_params, timeout=15)
            except Exception as e:
                print(f"‚ùå {self.source_name}: –æ—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
                break

            try:
                data = response.json()
            except Exception:
                data = {}

            if data.get('type') == 'ERROR':
                print(f"‚ùå {self.source_name} API –≤–µ—Ä–Ω—É–ª–æ –æ—à–∏–±–∫—É: {data.get('error')}")
                break

            jobs_on_page_raw = (data or {}).get('jobs', []) or []
            if not jobs_on_page_raw:
                break

            normalized_jobs: List[JobVacancy] = []
            for job_data in jobs_on_page_raw:
                country_name = self._get_country_name_by_code(country_code)
                job = self._normalize_job_data(job_data, country_name, keywords)
                if job:
                    normalized_jobs.append(job)

            total_jobs.extend(normalized_jobs)

            # –ö–ª–∞–¥—ë–º –ø–æ—Ä—Ü–∏—é –≤ –∫–µ—à –∏ –ø—É—à–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞ UI
            cache_key_params = {'keywords': keywords, 'location': location, 'country_code': country_code, 'page': page}
            self.cache_manager.cache_result(cache_key_params, normalized_jobs)
            print(f"üìÑ {self.source_name}: {location} ‚Äî —Å—Ç—Ä. {page}, –Ω–∞–π–¥–µ–Ω–æ: {len(normalized_jobs)}")

            if progress_callback and normalized_jobs:
                try:
                    progress_callback(normalized_jobs)
                except Exception:
                    pass

            # –ü–∞–≥–∏–Ω–∞—Ü–∏—è
            if len(jobs_on_page_raw) < (data.get('pagesize') or 50):
                break
            page += 1
            time.sleep(0.3)

        return total_jobs



    def _normalize_job_data(self, raw_job: Dict, country_name: str, search_term: str) -> Optional[JobVacancy]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç API –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç JobVacancy.
        """
        try:
            title = raw_job.get('title', '')
            description = raw_job.get('description', '')
            if not self.is_relevant_job(title, description, search_term):
                return None

            url = raw_job.get('url')
            if not url:
                return None
            job_id = hashlib.md5(url.encode()).hexdigest()

            date_str = raw_job.get('date', '')
            try:
                posted_date = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z').strftime('%Y-%m-%d')
            except (ValueError, TypeError):
                posted_date = datetime.now().strftime('%Y-%m-%d')

            return JobVacancy(
                id=f"careerjet_{job_id}",
                title=title,
                company=raw_job.get('company', 'Not specified'),
                location=raw_job.get('locations', 'Not specified'),
                salary=raw_job.get('salary'),
                description=description,
                apply_url=url,
                source=self.source_name,
                posted_date=posted_date,
                country=country_name,
                job_type=None,
                language_requirement=self.determine_language_requirement(title, description),
                refugee_friendly=self.is_refugee_friendly(title, description, search_term)
            )
        except Exception as e:
            print(f"‚ö†Ô∏è {self.source_name}: –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return None

    def is_relevant_job(self, job_title: str, job_description: str, search_term: str) -> bool:
        """
        –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å.
        """
        search_terms = search_term.lower().split()
        title_lower = job_title.lower()
        
        return any(term in title_lower for term in search_terms if len(term) > 2)

    def _get_country_name_by_code(self, country_code: str) -> str:
        """
        –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Å—Ç—Ä–∞–Ω—ã –ø–æ –∫–æ–¥—É.
        """
        return self.adzuna_countries.get(country_code, {}).get('name', country_code.upper())

    def _deduplicate_jobs(self, jobs: List[JobVacancy]) -> List[JobVacancy]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É."""
        seen = set()
        unique_jobs = []
        for job in jobs:
            if job.apply_url not in seen:
                seen.add(job.apply_url)
                unique_jobs.append(job)
        return unique_jobs

if __name__ == '__main__':
    print("üöÄ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ CareerjetAggregator...")
    
    try:
        main_aggregator_for_test = GlobalJobAggregator()
        aggregator = CareerjetAggregator(
            adzuna_countries=main_aggregator_for_test.countries,
            specific_jobs_map=main_aggregator_for_test.specific_jobs
        )
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞: {e}")
        aggregator = None

    if aggregator:
        test_preferences = {
            'selected_jobs': ['–ó–∞–ø—Ä–∞–≤—â–∏–∫ –Ω–∞ –ê–ó–°', '–û–ø–µ—Ä–∞—Ç–æ—Ä –ê–ó–°'],
            'countries': ['us'],
            'cities': [] # <-- –¢–µ—Å—Ç–∏—Ä—É–µ–º –±–µ–∑ –≥–æ—Ä–æ–¥–∞
        }
        
        start_time = time.time()
        found_jobs = aggregator.search_jobs(test_preferences)
        end_time = time.time()
        
        print(f"\n\n--- –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ê ---")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(found_jobs)}")
        
        if found_jobs:
            print("\nüìù –ü—Ä–∏–º–µ—Ä 5 –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π:")
            for i, job in enumerate(found_jobs[:5]):
                print(f"  {i+1}. {job.title} –≤ {job.company} ({job.location})")
                print(f"     –°—Å—ã–ª–∫–∞: {job.apply_url}")
