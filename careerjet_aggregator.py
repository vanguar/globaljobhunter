#!/usr/bin/env python3
"""
Careerjet Aggregator for GlobalJobHunter
"""

import os
import requests
import time
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import asdict
import hashlib
from dotenv import load_dotenv

# --- –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ adzuna_aggregator ---
from adzuna_aggregator import JobVacancy, CacheManager, RateLimiter, GlobalJobAggregator

# --- –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---
from base_aggregator import BaseJobAggregator

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

class CareerjetAggregator(BaseJobAggregator):
    """
    –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ Careerjet API.
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–æ–∏—Å–∫ –∫–∞–∫ –ø–æ —Å—Ç—Ä–∞–Ω–µ, —Ç–∞–∫ –∏ –ø–æ –≥–æ—Ä–æ–¥—É.
    - **–ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞:** –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.
    """
    def __init__(self, adzuna_countries: Dict, specific_jobs_map: Dict, cache_duration_hours: int = 12):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞.
        """
        super().__init__(source_name='Careerjet')
        self.base_url = "http://public.api.careerjet.net/search"
        
        self.affid = os.getenv('CAREERJET_AFFID')
        if not self.affid:
            raise ValueError("CAREERJET_AFFID –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")

        self.cache_manager = CacheManager(cache_duration_hours=cache_duration_hours)
        self.rate_limiter = RateLimiter(requests_per_minute=25)
        
        self.country_map = {
            'gb': 'United Kingdom', 'us': 'United States', 'de': 'Germany',
            'fr': 'France', 'es': 'Spain', 'it': 'Italy', 'nl': 'Netherlands',
            'pl': 'Poland', 'ca': 'Canada', 'au': 'Australia', 'at': 'Austria',
            'ch': 'Switzerland', 'be': 'Belgium', 'se': 'Sweden', 'no': 'Norway',
            'dk': 'Denmark', 'cz': 'Czech Republic', 'sk': 'Slovakia'
        }

        self.adzuna_countries = adzuna_countries
        self.specific_jobs_map = specific_jobs_map

        print(f"‚úÖ Careerjet Aggregator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (affid: ...{self.affid[-4:]})")

    def get_supported_countries(self) -> Dict[str, Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–∞–Ω, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —ç—Ç–∏–º –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–æ–º."""
        return {}

    def search_jobs(self, preferences: Dict, progress_callback=None, cancel_check=None) -> List[JobVacancy]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞. –ò—â–µ—Ç –ø–æ —Å—Ç—Ä–∞–Ω–µ, –∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –≥–æ—Ä–æ–¥ ‚Äî —É—Ç–æ—á–Ω—è–µ—Ç –ø–æ–∏—Å–∫.
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –¥–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –æ—Ç–¥–µ–ª—å–Ω–æ.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç:
        - progress_callback(list[JobVacancy]) –¥–ª—è "–∂–∏–≤–æ–≥–æ" —Å—á—ë—Ç—á–∏–∫–∞
        - cancel_check() –¥–ª—è –º—è–≥–∫–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
        """
        print(f"üì° {self.source_name}: –Ω–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫...")
        all_jobs: List[JobVacancy] = []
        
        selected_jobs = preferences.get('selected_jobs', [])
        countries = preferences.get('countries', [])
        cities = preferences.get('cities', [])

        if not selected_jobs or not countries:
            return []

        for russian_job_title in selected_jobs:
            # 1) –Ω–∞–π–¥—ë–º –∞–Ω–≥–ª. –∫–ª—é—á–∏ –∏–∑ specific_jobs_map
            english_keywords = []
            found = False
            for category in self.specific_jobs_map.values():
                if russian_job_title in category:
                    terms = category[russian_job_title][:3]
                    english_keywords.extend([t for t in terms if t])
                    found = True
                    break
            if not found:
                english_keywords.append(russian_job_title)

            if not english_keywords:
                continue

            keywords = " ".join(sorted(set(english_keywords)))
            print(f"‚ÑπÔ∏è {self.source_name}: '{russian_job_title}' ‚Üí '{keywords}'")

            for country_code in countries:
                if cancel_check and cancel_check():
                    return self._deduplicate_jobs(all_jobs)

                country_name_for_api = self.country_map.get(country_code)
                if not country_name_for_api:
                    continue

                if cities:
                    for city in cities:
                        if cancel_check and cancel_check():
                            return self._deduplicate_jobs(all_jobs)

                        search_location = f"{city}, {country_name_for_api}"
                        page_jobs = self._fetch_all_pages(
                            keywords, search_location, country_code,
                            progress_callback=progress_callback, cancel_check=cancel_check
                        )
                        if page_jobs:
                            all_jobs.extend(page_jobs)
                else:
                    search_location = country_name_for_api
                    page_jobs = self._fetch_all_pages(
                        keywords, search_location, country_code,
                        progress_callback=progress_callback, cancel_check=cancel_check
                    )
                    if page_jobs:
                        all_jobs.extend(page_jobs)

        print(f"‚úÖ {self.source_name}: –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ–≥–æ: {len(all_jobs)}")
        return self._deduplicate_jobs(all_jobs)


    def _fetch_all_pages(
    self,
    keywords: str,
    location: str,
    country_code: str,
    progress_callback=None,
    cancel_check=None
) -> List[JobVacancy]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ –≤—Å–µ—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏.
        –ö–ê–ñ–î–£–Æ —Å—Ç—Ä–∞–Ω–∏—Ü—É –æ—Ç–¥–∞—ë—Ç –±–∞—Ç—á–µ–º —á–µ—Ä–µ–∑ progress_callback(normalized_jobs).
        –£–≤–∞–∂–∞–µ—Ç cancel_check() –¥–ª—è –º—è–≥–∫–æ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–∏.
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–æ–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–Ω—ã–π –∫–µ—à (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ ‚Üí —Å–ø–∏—Å–æ–∫ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π).
        """
        page = 1
        total_jobs: List[JobVacancy] = []

        while True:
            if cancel_check and cancel_check():
                break

            search_params = {
                'affid': self.affid,
                'keywords': keywords,
                'location': location,
                'page': page,
                'sort': 'date',
                'user_ip': '127.0.0.1',
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'
            }
            # –∫–ª—é—á –∫–µ—à–∞ ‚Äî –±–µ–∑ user_* –ø–æ–ª–µ–π
            cache_key_params = {k: v for k, v in search_params.items() if k not in ['user_ip', 'user_agent']}

            cached_result = self.cache_manager.get_cached_result(cache_key_params)
            if cached_result:
                total_jobs.extend(cached_result)
                # –æ—Ç–¥–∞—Ç—å –±–∞—Ç—á –∏–∑ –∫–µ—à–∞ –¥–ª—è –∂–∏–≤–æ–≥–æ —Å—á—ë—Ç—á–∏–∫–∞
                if progress_callback and cached_result:
                    try:
                        progress_callback(cached_result)
                    except Exception:
                        pass
                # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –æ–∫–æ–Ω—á–∞–Ω–∏—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
                if len(cached_result) < 50:
                    break
                page += 1
                continue

            if hasattr(self, 'rate_limiter'):
                ok = self.rate_limiter.wait_if_needed(cancel_check=cancel_check) if hasattr(self, 'rate_limiter') else True
                if cancel_check and cancel_check():
                    return total_jobs
                if ok is False:
                    return total_jobs



            try:
                response = requests.get(self.base_url, params=search_params, timeout=15)
                if response.status_code != 200:
                    print(f"‚ùå {self.source_name} API {response.status_code}: {response.text}")
                    break

                data = response.json()
                if data.get('type') == 'ERROR':
                    print(f"‚ùå {self.source_name} API error: {data.get('error')}")
                    break

                jobs_on_page_raw = data.get('jobs', [])
                if not jobs_on_page_raw:
                    break

                normalized_jobs: List[JobVacancy] = []
                country_name = self._get_country_name_by_code(country_code)
                for job_data in jobs_on_page_raw:
                    job = self._normalize_job_data(job_data, country_name, keywords)
                    if job:
                        normalized_jobs.append(job)

                total_jobs.extend(normalized_jobs)
                # –∫–µ—à–∏—Ä—É–µ–º –∏–º–µ–Ω–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ —ç—Ç–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
                self.cache_manager.cache_result(cache_key_params, normalized_jobs)
                print(f"üìÑ {self.source_name}: {location} ‚Äî —Å—Ç—Ä. {page}, –Ω–∞–π–¥–µ–Ω–æ: {len(normalized_jobs)}")

                # –û–¢–î–ê–Å–ú –ë–ê–¢–ß –î–õ–Ø –ñ–ò–í–û–ì–û –ü–†–û–ì–†–ï–°–°–ê
                if progress_callback and normalized_jobs:
                    try:
                        progress_callback(normalized_jobs)
                    except Exception:
                        pass

                # –∫–æ–Ω–µ—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏?
                if len(jobs_on_page_raw) < data.get('pagesize', 50):
                    break

                page += 1
                time.sleep(0.5)

            except requests.Timeout:
                print(f"‚ö†Ô∏è {self.source_name}: —Ç–∞–π–º–∞—É—Ç, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –¥–ª—è '{location}'")
                break
            except Exception as e:
                print(f"‚ùå {self.source_name}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
                break

        return total_jobs


    def _normalize_job_data(self, raw_job: Dict, country_name: str, search_term: str) -> Optional[JobVacancy]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç API –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç JobVacancy.
        """
        try:
            title = raw_job.get('title', '')
            description = raw_job.get('description', '')
            if not self.is_relevant_job(title, description, search_term):
                return None

            url = raw_job.get('url')
            if not url:
                return None
            job_id = hashlib.md5(url.encode()).hexdigest()

            date_str = raw_job.get('date', '')
            try:
                posted_date = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z').strftime('%Y-%m-%d')
            except (ValueError, TypeError):
                posted_date = datetime.now().strftime('%Y-%m-%d')

            return JobVacancy(
                id=f"careerjet_{job_id}",
                title=title,
                company=raw_job.get('company', 'Not specified'),
                location=raw_job.get('locations', 'Not specified'),
                salary=raw_job.get('salary'),
                description=description,
                apply_url=url,
                source=self.source_name,
                posted_date=posted_date,
                country=country_name,
                job_type=None,
                language_requirement=self.determine_language_requirement(title, description),
                refugee_friendly=self.is_refugee_friendly(title, description, search_term)
            )
        except Exception as e:
            print(f"‚ö†Ô∏è {self.source_name}: –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return None

    def is_relevant_job(self, job_title: str, job_description: str, search_term: str) -> bool:
        """
        –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å.
        """
        search_terms = search_term.lower().split()
        title_lower = job_title.lower()
        
        return any(term in title_lower for term in search_terms if len(term) > 2)

    def _get_country_name_by_code(self, country_code: str) -> str:
        """
        –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Å—Ç—Ä–∞–Ω—ã –ø–æ –∫–æ–¥—É.
        """
        return self.adzuna_countries.get(country_code, {}).get('name', country_code.upper())

    def _deduplicate_jobs(self, jobs: List[JobVacancy]) -> List[JobVacancy]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É."""
        seen = set()
        unique_jobs = []
        for job in jobs:
            if job.apply_url not in seen:
                seen.add(job.apply_url)
                unique_jobs.append(job)
        return unique_jobs

if __name__ == '__main__':
    print("üöÄ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ CareerjetAggregator...")
    
    try:
        main_aggregator_for_test = GlobalJobAggregator()
        aggregator = CareerjetAggregator(
            adzuna_countries=main_aggregator_for_test.countries,
            specific_jobs_map=main_aggregator_for_test.specific_jobs
        )
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞: {e}")
        aggregator = None

    if aggregator:
        test_preferences = {
            'selected_jobs': ['–ó–∞–ø—Ä–∞–≤—â–∏–∫ –Ω–∞ –ê–ó–°', '–û–ø–µ—Ä–∞—Ç–æ—Ä –ê–ó–°'],
            'countries': ['us'],
            'cities': [] # <-- –¢–µ—Å—Ç–∏—Ä—É–µ–º –±–µ–∑ –≥–æ—Ä–æ–¥–∞
        }
        
        start_time = time.time()
        found_jobs = aggregator.search_jobs(test_preferences)
        end_time = time.time()
        
        print(f"\n\n--- –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ê ---")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(found_jobs)}")
        
        if found_jobs:
            print("\nüìù –ü—Ä–∏–º–µ—Ä 5 –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π:")
            for i, job in enumerate(found_jobs[:5]):
                print(f"  {i+1}. {job.title} –≤ {job.company} ({job.location})")
                print(f"     –°—Å—ã–ª–∫–∞: {job.apply_url}")
