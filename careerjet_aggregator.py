#!/usr/bin/env python3
"""
Careerjet Aggregator for GlobalJobHunter
"""

import os
import requests
import time
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import asdict
import hashlib
from dotenv import load_dotenv

# --- –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ adzuna_aggregator ---
from adzuna_aggregator import JobVacancy, CacheManager, RateLimiter, GlobalJobAggregator

# --- –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---
from base_aggregator import BaseJobAggregator

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

class CareerjetAggregator(BaseJobAggregator):
    """
    –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ Careerjet API.
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–æ–∏—Å–∫ –∫–∞–∫ –ø–æ —Å—Ç—Ä–∞–Ω–µ, —Ç–∞–∫ –∏ –ø–æ –≥–æ—Ä–æ–¥—É.
    - **–ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞:** –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.
    """
    def __init__(self, adzuna_countries: Dict, specific_jobs_map: Dict, cache_duration_hours: int = 12):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–∞.
        """
        super().__init__(source_name='Careerjet')
        self.base_url = "http://public.api.careerjet.net/search"
        
        self.affid = os.getenv('CAREERJET_AFFID')
        if not self.affid:
            raise ValueError("CAREERJET_AFFID –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env —Ñ–∞–π–ª–µ!")

        self.cache_manager = CacheManager(cache_duration_hours=cache_duration_hours)
        self.rate_limiter = RateLimiter(requests_per_minute=25)
        
        self.country_map = {
            'gb': 'United Kingdom', 'us': 'United States', 'de': 'Germany',
            'fr': 'France', 'es': 'Spain', 'it': 'Italy', 'nl': 'Netherlands',
            'pl': 'Poland', 'ca': 'Canada', 'au': 'Australia', 'at': 'Austria',
            'ch': 'Switzerland', 'be': 'Belgium', 'se': 'Sweden', 'no': 'Norway',
            'dk': 'Denmark', 'cz': 'Czech Republic', 'sk': 'Slovakia'
        }

        self.adzuna_countries = adzuna_countries
        self.specific_jobs_map = specific_jobs_map

        print(f"‚úÖ Careerjet Aggregator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (affid: ...{self.affid[-4:]})")

    def get_supported_countries(self) -> Dict[str, Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–∞–Ω, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —ç—Ç–∏–º –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–æ–º."""
        return {}

    def search_jobs(self, preferences: Dict) -> List[JobVacancy]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞. –ò—â–µ—Ç –ø–æ —Å—Ç—Ä–∞–Ω–µ, –∏ –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –≥–æ—Ä–æ–¥ - —É—Ç–æ—á–Ω—è–µ—Ç –ø–æ–∏—Å–∫.
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø–æ–∏—Å–∫ –¥–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –æ—Ç–¥–µ–ª—å–Ω–æ.
        """
        print(f"ÔøΩ {self.source_name}: –ù–∞—á–∏–Ω–∞–µ–º –ø–æ–∏—Å–∫...")
        all_jobs: List[JobVacancy] = []
        
        selected_jobs = preferences.get('selected_jobs', [])
        countries = preferences.get('countries', [])
        cities = preferences.get('cities', [])

        if not selected_jobs or not countries:
            return []

        # --- –ò–ó–ú–ï–ù–ï–ù–ò–ï: –ò—Ç–µ—Ä–∞—Ü–∏—è –ø–æ –∫–∞–∂–¥–æ–π –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ ---
        for russian_job_title in selected_jobs:
            # 1. –ù–∞—Ö–æ–¥–∏–º –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –û–î–ù–û–ô –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏
            english_keywords = []
            found = False
            for category in self.specific_jobs_map.values():
                if russian_job_title in category:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 —Ç–µ—Ä–º–∏–Ω–∞ (–æ–Ω–∏ –≤—Å–µ–≥–¥–∞ –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º)
                    english_terms = category[russian_job_title][:3]
                    english_keywords.extend([term for term in english_terms if term])
                    found = True
                    break
            if not found:
                english_keywords.append(russian_job_title)
            
            if not english_keywords:
                continue

            keywords = " ".join(list(set(english_keywords)))
            print(f"‚ÑπÔ∏è {self.source_name}: –ò—â–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏—é '{russian_job_title}' –ø–æ —Å–ª–æ–≤–∞–º: '{keywords}'")

            # 2. –ò—â–µ–º —ç—Ç—É –ø—Ä–æ—Ñ–µ—Å—Å–∏—é –ø–æ –≤—Å–µ–º —Å—Ç—Ä–∞–Ω–∞–º –∏ –≥–æ—Ä–æ–¥–∞–º
            for country_code in countries:
                country_name_for_api = self.country_map.get(country_code)
                if not country_name_for_api:
                    continue

                if cities:
                    for city in cities:
                        search_location = f"{city}, {country_name_for_api}"
                        jobs = self._fetch_all_pages(keywords, search_location, country_code)
                        all_jobs.extend(jobs)
                else:
                    search_location = country_name_for_api
                    jobs = self._fetch_all_pages(keywords, search_location, country_code)
                    all_jobs.extend(jobs)
        # --- –ö–û–ù–ï–¶ –ò–ó–ú–ï–ù–ï–ù–ò–ô ---

        print(f"‚úÖ {self.source_name}: –ü–æ–∏—Å–∫ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ –≤—Å–µ–≥–æ: {len(all_jobs)} –≤–∞–∫–∞–Ω—Å–∏–π.")
        return self._deduplicate_jobs(all_jobs)

    def _fetch_all_pages(self, keywords: str, location: str, country_code: str) -> List[JobVacancy]:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –≤–∞–∫–∞–Ω—Å–∏–∏ —Å–æ –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏.
        """
        page = 1
        total_jobs: List[JobVacancy] = []
        
        while True:
            search_params = {
                'affid': self.affid,
                'keywords': keywords,
                'location': location,
                'page': page,
                'sort': 'date',
                'user_ip': '127.0.0.1', 
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'
            }
            
            cache_key_params = {k: v for k, v in search_params.items() if k not in ['user_ip', 'user_agent']}

            cached_result = self.cache_manager.get_cached_result(cache_key_params)
            if cached_result:
                total_jobs.extend(cached_result)
                if len(cached_result) < 50:
                    break
                page += 1
                continue

            self.rate_limiter.wait_if_needed()
            
            try:
                response = requests.get(self.base_url, params=search_params, timeout=15)
                
                if response.status_code != 200:
                    print(f"‚ùå {self.source_name} API –æ—à–∏–±–∫–∞ {response.status_code}: {response.text}")
                    break

                data = response.json()
                
                if data.get('type') == 'ERROR':
                    print(f"‚ùå {self.source_name} API –≤–µ—Ä–Ω—É–ª–æ –æ—à–∏–±–∫—É: {data.get('error')}")
                    break

                jobs_on_page_raw = data.get('jobs', [])
                if not jobs_on_page_raw:
                    break
                
                normalized_jobs = []
                for job_data in jobs_on_page_raw:
                    country_name = self._get_country_name_by_code(country_code)
                    job = self._normalize_job_data(job_data, country_name, keywords)
                    if job:
                        normalized_jobs.append(job)

                total_jobs.extend(normalized_jobs)
                
                self.cache_manager.cache_result(cache_key_params, normalized_jobs)
                
                print(f"üìÑ {self.source_name}: –û–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page} –¥–ª—è '{location}'. –ù–∞–π–¥–µ–Ω–æ: {len(normalized_jobs)}.")

                if len(jobs_on_page_raw) < data.get('pagesize', 50):
                    break
                    
                page += 1
                time.sleep(0.5)

            except requests.Timeout:
                print(f"‚ö†Ô∏è {self.source_name}: –¢–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞. –ü—Ä–µ—Ä—ã–≤–∞–µ–º –ø–æ–∏—Å–∫ –¥–ª—è '{location}'.")
                break
            except Exception as e:
                print(f"‚ùå {self.source_name}: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ: {e}")
                break
                
        return total_jobs

    def _normalize_job_data(self, raw_job: Dict, country_name: str, search_term: str) -> Optional[JobVacancy]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç API –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç JobVacancy.
        """
        try:
            title = raw_job.get('title', '')
            description = raw_job.get('description', '')
            if not self.is_relevant_job(title, description, search_term):
                return None

            url = raw_job.get('url')
            if not url:
                return None
            job_id = hashlib.md5(url.encode()).hexdigest()

            date_str = raw_job.get('date', '')
            try:
                posted_date = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z').strftime('%Y-%m-%d')
            except (ValueError, TypeError):
                posted_date = datetime.now().strftime('%Y-%m-%d')

            return JobVacancy(
                id=f"careerjet_{job_id}",
                title=title,
                company=raw_job.get('company', 'Not specified'),
                location=raw_job.get('locations', 'Not specified'),
                salary=raw_job.get('salary'),
                description=description,
                apply_url=url,
                source=self.source_name,
                posted_date=posted_date,
                country=country_name,
                job_type=None,
                language_requirement=self.determine_language_requirement(title, description),
                refugee_friendly=self.is_refugee_friendly(title, description, search_term)
            )
        except Exception as e:
            print(f"‚ö†Ô∏è {self.source_name}: –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return None

    def is_relevant_job(self, job_title: str, job_description: str, search_term: str) -> bool:
        """
        –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å.
        """
        search_terms = search_term.lower().split()
        title_lower = job_title.lower()
        
        return any(term in title_lower for term in search_terms if len(term) > 2)

    def _get_country_name_by_code(self, country_code: str) -> str:
        """
        –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Å—Ç—Ä–∞–Ω—ã –ø–æ –∫–æ–¥—É.
        """
        return self.adzuna_countries.get(country_code, {}).get('name', country_code.upper())

    def _deduplicate_jobs(self, jobs: List[JobVacancy]) -> List[JobVacancy]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É."""
        seen = set()
        unique_jobs = []
        for job in jobs:
            if job.apply_url not in seen:
                seen.add(job.apply_url)
                unique_jobs.append(job)
        return unique_jobs

if __name__ == '__main__':
    print("üöÄ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ CareerjetAggregator...")
    
    try:
        main_aggregator_for_test = GlobalJobAggregator()
        aggregator = CareerjetAggregator(
            adzuna_countries=main_aggregator_for_test.countries,
            specific_jobs_map=main_aggregator_for_test.specific_jobs
        )
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞: {e}")
        aggregator = None

    if aggregator:
        test_preferences = {
            'selected_jobs': ['–ó–∞–ø—Ä–∞–≤—â–∏–∫ –Ω–∞ –ê–ó–°', '–û–ø–µ—Ä–∞—Ç–æ—Ä –ê–ó–°'],
            'countries': ['us'],
            'cities': [] # <-- –¢–µ—Å—Ç–∏—Ä—É–µ–º –±–µ–∑ –≥–æ—Ä–æ–¥–∞
        }
        
        start_time = time.time()
        found_jobs = aggregator.search_jobs(test_preferences)
        end_time = time.time()
        
        print(f"\n\n--- –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ê ---")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(found_jobs)}")
        
        if found_jobs:
            print("\nüìù –ü—Ä–∏–º–µ—Ä 5 –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π:")
            for i, job in enumerate(found_jobs[:5]):
                print(f"  {i+1}. {job.title} –≤ {job.company} ({job.location})")
                print(f"     –°—Å—ã–ª–∫–∞: {job.apply_url}")
