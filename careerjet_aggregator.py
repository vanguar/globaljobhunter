#!/usr/bin/env python3
"""
Careerjet Aggregator for GlobalJobHunter
"""

import os
import requests
from requests.adapters import HTTPAdapter
try:
    from urllib3.util.retry import Retry
except Exception:
    Retry = None
import time
from datetime import datetime
from typing import List, Dict, Optional
from dataclasses import asdict
import hashlib
from dotenv import load_dotenv
import certifi

DEFAULT_CJ_REFERER = os.getenv("CAREERJET_REFERER", "https://globaljobhunter.vip/results")


# --- –ü–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ adzuna_aggregator ---
from adzuna_aggregator import JobVacancy, CacheManager, RateLimiter, GlobalJobAggregator

# --- –ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã ---
from base_aggregator import BaseJobAggregator

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–∑ .env —Ñ–∞–π–ª–∞
load_dotenv()

class CareerjetAggregator(BaseJobAggregator):
    """
    –ê–≥—Ä–µ–≥–∞—Ç–æ—Ä –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π —á–µ—Ä–µ–∑ Careerjet API.
    - –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–æ–∏—Å–∫ –∫–∞–∫ –ø–æ —Å—Ç—Ä–∞–Ω–µ, —Ç–∞–∫ –∏ –ø–æ –≥–æ—Ä–æ–¥—É.
    - **–ù–æ–≤–∞—è –ª–æ–≥–∏–∫–∞:** –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –¥–ª—è –±–æ–ª—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏.
    """
    def __init__(self, adzuna_countries: Dict, specific_jobs_map: Dict, cache_duration_hours: Optional[int] = None):
        super().__init__(source_name='Careerjet')
        self.base_url = "https://search.api.careerjet.net/v4/query"

        self.api_key = os.getenv('CAREERJET_API_KEY')
        if not self.api_key:
            raise ValueError("CAREERJET_API_KEY is not set")

        # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º affid, –µ—Å–ª–∏ –≥–¥–µ-—Ç–æ –Ω—É–∂–µ–Ω)
        self.affid = os.getenv('CAREERJET_AFFID', '')

        # –í—Å–µ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π CA-–±–∞–Ω–¥–ª –∏ –∑–∞–∫—Ä–µ–ø–ª—è–µ–º –µ–≥–æ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏
        self._cj_verify_path = os.getenv('REQUESTS_CA_BUNDLE') or os.getenv('SSL_CERT_FILE') or certifi.where()
        os.environ['SSL_CERT_FILE'] = self._cj_verify_path
        os.environ['REQUESTS_CA_BUNDLE'] = self._cj_verify_path
        print(f"üîê Careerjet TLS bundle: {self._cj_verify_path}")

        # TTL –∫–µ—à–∞ (—á–∞—Å—ã)
        if cache_duration_hours is None:
            try:
                cache_duration_hours = int(os.getenv('CAREERJET_CACHE_HOURS', os.getenv('CACHE_TTL_HOURS', '24')))
            except Exception:
                cache_duration_hours = 24

        self.cache_manager = CacheManager(cache_duration_hours=cache_duration_hours)
        self.rate_limiter = RateLimiter(requests_per_minute=25)
        self.cooldown_until = 0  # –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫—É–ª–¥–∞—É–Ω –ø—Ä–∏ 429

        # –°—Ç—Ä–∞–Ω—ã –∏ –Ω–∞–∑–≤–∞–Ω–∏—è
        self.country_map = {
            'gb': 'United Kingdom', 'us': 'United States', 'de': 'Germany',
            'fr': 'France', 'es': 'Spain', 'it': 'Italy', 'nl': 'Netherlands',
            'pl': 'Poland', 'ca': 'Canada', 'au': 'Australia', 'at': 'Austria',
            'ch': 'Switzerland', 'be': 'Belgium', 'se': 'Sweden', 'no': 'Norway',
            'dk': 'Denmark', 'cz': 'Czech Republic', 'sk': 'Slovakia', 'ua': 'Ukraine'
        }

        # locale_code –¥–ª—è Careerjet
        self.locale_map = {
            'gb': 'en_GB', 'us': 'en_US', 'de': 'de_DE', 'fr': 'fr_FR',
            'es': 'es_ES', 'it': 'it_IT', 'nl': 'nl_NL', 'pl': 'pl_PL',
            'ca': 'en_CA', 'au': 'en_AU', 'at': 'de_AT', 'ch': 'de_CH',
            'be': 'nl_BE', 'se': 'sv_SE', 'no': 'no_NO', 'dk': 'da_DK',
            'cz': 'cs_CZ', 'sk': 'sk_SK', 'ua': 'uk_UA'
        }

        self.adzuna_countries = adzuna_countries
        self.specific_jobs_map = specific_jobs_map

        # –°–µ—Å—Å–∏—è —Å —Ä–µ—Ç—Ä–∞—è–º–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        self.session = requests.Session()
        if Retry:
            retries = Retry(
                total=3,
                backoff_factor=0.6,
                status_forcelist=[429, 500, 502, 503, 504],
                allowed_methods=frozenset(["GET"])
            )
            self.session.mount("https://", HTTPAdapter(max_retries=retries))
        else:
            self.session.mount("https://", HTTPAdapter())

        print(f"‚úÖ Careerjet Aggregator –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (affid: ...{self.affid[-4:]})")

    def _terms_from_ru(self, ru_title: str) -> List[str]:
        """
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ø–æ–∏—Å–∫–æ–≤—ã—Ö —Ç–µ—Ä–º–æ–≤ (EN –∏ –¥—Ä.) –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏.
        –†–∞–±–æ—Ç–∞–µ—Ç —Å —Ä–∞–∑–Ω—ã–º–∏ —Ñ–æ—Ä–º–∞–º–∏ specific_jobs_map:
        - { <category>: { <ru_title>: [ "term1", "term2", ... ] } }
        - { <category>: { <ru_title>: { 'en': [...], 'keywords': { 'en': [...], 'de': [...], ... }, 'terms': [...] } } }
        """
        terms: List[str] = []

        # –≥–¥–µ –ª–µ–∂–∏—Ç –∫–∞—Ä—Ç–∞
        sj = getattr(self, "specific_jobs_map", None) or getattr(self, "specific_jobs", None) or {}

        # 1) –ø—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–∞ ru_title
        if isinstance(sj, dict):
            for _cat, ru_map in sj.items():
                if not isinstance(ru_map, dict):
                    continue
                if ru_title in ru_map:
                    val = ru_map[ru_title]
                    if isinstance(val, list):
                        terms.extend(val)
                    elif isinstance(val, dict):
                        # –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø–æ–ª—è
                        if isinstance(val.get("en"), list):
                            terms.extend(val["en"])
                        kw = val.get("keywords")
                        if isinstance(kw, dict):
                            for lst in kw.values():
                                if isinstance(lst, list):
                                    terms.extend(lst)
                        elif isinstance(kw, list):
                            terms.extend(kw)
                        if isinstance(val.get("terms"), list):
                            terms.extend(val["terms"])
                    break

        # 2) fallback: –µ—Å–ª–∏ ru_title –º–æ–≥–ª–∏ —Ö—Ä–∞–Ω–∏—Ç—å –≤ —Å–ø–∏—Å–∫–µ val['ru'] –∏ —Ç.–ø.
        if not terms and isinstance(sj, dict):
            for _cat, ru_map in sj.items():
                if not isinstance(ru_map, dict):
                    continue
                for _ru_key, val in ru_map.items():
                    if not isinstance(val, dict):
                        continue
                    ru_list = val.get("ru") or val.get("ru_terms")
                    if isinstance(ru_list, list) and ru_title in ru_list:
                        kw = val.get("keywords") or {}
                        if isinstance(kw, dict):
                            for lst in kw.values():
                                if isinstance(lst, list):
                                    terms.extend(lst)
                        if isinstance(val.get("en"), list):
                            terms.extend(val["en"])
                        if isinstance(val.get("terms"), list):
                            terms.extend(val["terms"])
                        break

        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —É–Ω–∏–∫–∞–ª–∏–∑–∏—Ä—É–µ–º, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫
        seen = set()
        uniq = []
        for t in terms:
            t = (t or "").strip()
            if not t:
                continue
            key = t.lower()
            if key not in seen:
                uniq.append(t)
                seen.add(key)
        return uniq
    
    def get_supported_countries(self) -> Dict[str, Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å—Ç—Ä–∞–Ω, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —ç—Ç–∏–º –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä–æ–º."""
        return {}

    def search_jobs(self, preferences: Dict, progress_callback=None, cancel_check=None,
                user_ip: str = '0.0.0.0', user_agent: str = 'Mozilla/5.0', page_url: str = '') -> List[JobVacancy]:
        """
        –ü–æ–∏—Å–∫ –Ω–∞ Careerjet –ü–û –ö–ê–ñ–î–û–ú–£ –¢–ï–†–ú–ò–ù–£ –æ—Ç–¥–µ–ª—å–Ω–æ.
        - –ñ—ë—Å—Ç–∫–æ —É–≤–∞–∂–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏ –∏–∑ preferences['selected_jobs'].
        - –ù–µ –∫–µ—à–∏—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—á—Ç–æ–±—ã –Ω–µ ¬´–∑–∞—Å—Ç—ã–≤–∞–ª–∏ –Ω—É–ª–∏¬ª).
        - –ü–∞–≥–∏–Ω–∞—Ü–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–∞–Ω–∏—Ü –∏ –∑–∞—â–∏—Ç–æ–π –æ—Ç –¥—É–±–ª–∏–∫–∞—Ç–æ–≤.
        - cancel_check() –º—è–≥–∫–æ –ø—Ä–µ—Ä—ã–≤–∞–µ—Ç —Ü–∏–∫–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —É–∂–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ.
        """
        all_jobs: List[JobVacancy] = []

        # –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫—É–ª–¥–∞—É–Ω –∏—Å—Ç–æ—á–Ω–∏–∫–∞
        now = time.time()
        if getattr(self, "cooldown_until", 0) > now:
            left = int(self.cooldown_until - now)
            print(f"‚õî Careerjet: –Ω–∞ cooldown –µ—â—ë {left}s ‚Äî –∏—Å—Ç–æ—á–Ω–∏–∫ –≤—Ä–µ–º–µ–Ω–Ω–æ –ø—Ä–æ–ø—É—â–µ–Ω.")
            return []

        # –≤—Ö–æ–¥–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
        selected_jobs: List[str] = preferences.get('selected_jobs', []) or []
        countries: List[str] = preferences.get('countries', []) or []
        cities: List[str] = preferences.get('cities', []) or []

        if not selected_jobs or not countries:
            return []

        # –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü –Ω–∞ –æ–¥–∏–Ω term
        try:
            max_pages = int(os.getenv("CAREERJET_MAX_PAGES_PER_TERM", "15"))
        except Exception:
            max_pages = 15
        max_pages = min(max_pages, 10)
        
        # –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
        for ru_title in selected_jobs:
            if cancel_check and cancel_check():
                break

            # === –í–ê–ñ–ù–û: –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ —Ç–µ—Ä–º—ã —ç—Ç–æ–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–∏; –µ—Å–ª–∏ –º–∞–ø–ø–∏–Ω–≥–∞ –Ω–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º ===
            en_terms = list(dict.fromkeys([t for t in self._terms_from_ru(ru_title) if t]))
            if not en_terms:
                # –Ω–µ—Ç –º–∞–ø–ø–∏–Ω–≥–∞ ‚Äî –≤–æ–æ–±—â–µ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º —ç—Ç–æ—Ç ru_title
                continue

            print(f"üì° Careerjet: '{ru_title}' ‚Üí —Ç–µ—Ä–º—ã: {', '.join(en_terms)}")

            for cc in countries:
                if cancel_check and cancel_check():
                    break

                country_name = self.country_map.get(cc)
                if not country_name:
                    continue
                locale_code = self._get_locale_code(cc)

                locations = [f"{city}, {country_name}" for city in cities] if cities else [country_name]
                for loc in locations:
                    if cancel_check and cancel_check():
                        break

                    for idx, term in enumerate(en_terms, 1):
                        if cancel_check and cancel_check():
                            break

                        # 1) –ü–æ–ø—ã—Ç–∫–∞ –∏–∑ —Å—É–±–∫–µ—à–∞ (–ø—É—Å—Ç—ã–µ –º—ã —Ç–∞–º –Ω–µ —Ö—Ä–∞–Ω–∏–º)
                        cached = self.cache_manager.get_term_cached_result(cc, loc, term)
                        if cached is not None:
                            print(f"    üíæ Subcache HIT Careerjet [{cc}/{loc}] term='{term}': {len(cached)}")
                            if cached and progress_callback:
                                try:
                                    progress_callback(cached)
                                except Exception:
                                    pass
                            all_jobs.extend(cached or [])
                            continue

                        print(f"    üîç Careerjet [{cc}/{loc}] term {idx}/{len(en_terms)}: '{term}'")
                        page = 1
                        collected_for_term: List[JobVacancy] = []
                        seen_urls_for_term: set[str] = set()

                        while True:
                            if cancel_check and cancel_check():
                                break

                            batch = self._request_page(
                                term=term,
                                location=loc,
                                country_name=country_name,
                                locale_code=locale_code,
                                page=page,
                                user_ip=user_ip,
                                user_agent=user_agent,
                                page_url=page_url
                            )


                            # None ‚Üí 429/cooldown ‚Äî –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –ø–æ —ç—Ç–æ–º—É term
                            if batch is None:
                                break

                            # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ ‚Äî –∫–æ–Ω–µ—Ü –ø–∞–≥–∏–Ω–∞—Ü–∏–∏
                            if not batch:
                                if page == 1:
                                    print(f"    üìÑ Careerjet: {loc} term='{term}' page 1: +0")
                                break

                            # —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ —Ä–∞–º–∫–∞—Ö term
                            new_batch: List[JobVacancy] = []
                            for j in batch:
                                url_or_id = getattr(j, "apply_url", None) or getattr(j, "id", None)
                                if not url_or_id or url_or_id in seen_urls_for_term:
                                    continue
                                seen_urls_for_term.add(url_or_id)
                                new_batch.append(j)

                            if not new_batch:
                                print(f"üîÅ Careerjet: {loc} term='{term}' page {page}: —Ç–æ–ª—å–∫–æ –¥—É–±–ª–∏–∫–∞—Ç—ã ‚Äî —Å—Ç–æ–ø.")
                                break

                            # –ø—Ä–æ–≥—Ä–µ—Å—Å –Ω–∞—Ä—É–∂—É
                            if progress_callback:
                                try:
                                    progress_callback(new_batch)
                                except Exception:
                                    pass

                            collected_for_term.extend(new_batch)
                            all_jobs.extend(new_batch)

                            page += 1
                            if page > max_pages:
                                print(f"‚èπ Careerjet: –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç —Å—Ç—Ä–∞–Ω–∏—Ü {max_pages} –¥–ª—è term='{term}' [{loc}]")
                                break

                        # 2) –∫–µ—à–∏—Ä—É–µ–º –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —á—Ç–æ-—Ç–æ –Ω–∞—à–ª–∏
                        if collected_for_term:
                            try:
                                self.cache_manager.cache_term_result(cc, loc, term, collected_for_term)
                            except Exception:
                                pass

        return self._deduplicate_jobs(all_jobs)




    
    def _request_page(self, term: str, location: str, country_name: str, locale_code: str, page: int,
                  *, user_ip: str, user_agent: str, page_url: str) -> Optional[List[JobVacancy]]:
        """
        –û–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –∫ Careerjet.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
            - list[JobVacancy] ‚Äî –µ—Å–ª–∏ —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤–∞–∫–∞–Ω—Å–∏–∏,
            - [] ‚Äî –µ—Å–ª–∏ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–µ—Ç/—Å—Ç—Ä–∞–Ω–∏—Ü –±–æ–ª—å—à–µ –Ω–µ—Ç,
            - None ‚Äî –µ—Å–ª–∏ –ø–æ–ª—É—á–µ–Ω 429 –∏ –≤–∫–ª—é—á—ë–Ω cooldown.
        """
        # –≥–ª–æ–±–∞–ª—å–Ω—ã–π –∫—É–ª–¥–∞—É–Ω –ø–æ—Å–ª–µ 429
        now = time.time()
        if getattr(self, "cooldown_until", 0) > now:
            return []

        params = {
            'locale_code': locale_code,
            'keywords': term,
            'location': location or '',
            'page': page,             # 1..10
            'page_size': 20,          # 1..100
            'user_ip': user_ip,       # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
            'user_agent': user_agent, # –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û
        }

        dbg = dict(params)
        dbg['user_ip'] = (str(dbg.get('user_ip'))[:7] + "xxx") if dbg.get('user_ip') else None
        print("CJ PARAMS =>", dbg, flush=True)

        headers = {
            'Accept': 'application/json',
            'Referer': page_url or os.getenv("CAREERJET_REFERER", "https://www.globaljobhunter.vip/results"),
            'User-Agent': user_agent or 'Mozilla/5.0',
        }

        def _do_get(p, verify_mode=None):
            if verify_mode is None:
                verify_mode = self._cj_verify_path  # pinned certifi bundle
            return self.session.get(
                self.base_url,
                params=p,
                auth=(self.api_key, ''),     # Basic Auth: username=API_KEY, –ø–∞—Ä–æ–ª—å –ø—É—Å—Ç–æ–π
                headers=headers,
                timeout=15,
                verify=verify_mode,
            )

        try:
            self.rate_limiter.wait_if_needed()

            # –ü–æ–ø—ã—Ç–∫–∞ 1: –æ–±—ã—á–Ω–∞—è —Å –Ω–∞—à–∏–º pinned CA-–±–∞–Ω–¥–ª–æ–º
            try:
                r = _do_get(params)
            except requests.exceptions.SSLError as e1:
                print(f"‚ö†Ô∏è SSL error with pinned bundle ‚Üí try certifi.where(): {e1}")
                # –ü–æ–ø—ã—Ç–∫–∞ 2: —è–≤–Ω—ã–π certifi.where()
                try:
                    r = _do_get(params, verify_mode=certifi.where())
                except requests.exceptions.SSLError as e2:
                    print(f"‚ö†Ô∏è SSL still failing ‚Üí try verify=False only if CJ_INSECURE=1: {e2}")
                    # –ü–æ–ø—ã—Ç–∫–∞ 3: –±–µ–∑ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏)
                    if os.getenv("CJ_INSECURE") == "1":
                        r = _do_get(params, verify_mode=False)
                    else:
                        # –ü–æ–ø—ã—Ç–∫–∞ 4: —Å—Ç–∞—Ä—ã–π HTTP API –∫–∞–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–π —à–∞–Ω—Å (–≤—Ä–µ–º–µ–Ω–Ω—ã–π –æ–±—Ö–æ–¥)
                        if os.getenv("CJ_USE_OLD_HTTP") == "1":
                            return self._fallback_old_api(term, location, locale_code, page, user_ip, user_agent, page_url)
                        # –µ—Å–ª–∏ —Ñ–æ–ª–±—ç–∫ –≤—ã–∫–ª—é—á–µ–Ω ‚Äî —Ñ–∏–∫—Å–∏—Ä—É–µ–º –æ—à–∏–±–∫—É –∏ –≤—ã—Ö–æ–¥–∏–º
                        print(f"‚ùå Careerjet: SSL error page={page} [{location}] term='{term}': {e2}")
                        return []

            # 429 ‚Üí –∫—É–ª–¥–∞—É–Ω –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –ø–æ–∑–∂–µ
            if r.status_code == 429:
                cd = float(os.getenv('CAREERJET_COOLDOWN_SEC', '150'))
                self.cooldown_until = time.time() + cd
                print(f"‚õî Careerjet: HTTP 429 ‚Üí cooldown {int(cd)}s (term='{term}', loc='{location}')")
                return None

            if r.status_code != 200:
                print(f"‚ùå Careerjet: HTTP {r.status_code} page={page} [{location}] term='{term}'")
                # –ø—Ä–∏ –Ω–µ-200 –º–æ–∂–Ω–æ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–π HTTP, –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ
                if os.getenv("CJ_USE_OLD_HTTP") == "1":
                    return self._fallback_old_api(term, location, locale_code, page, user_ip, user_agent, page_url)
                return []

            data = r.json() or {}

            # –†–µ–∂–∏–º –≤—ã–±–æ—Ä–∞ –ª–æ–∫–∞—Ü–∏–∏
            if data.get('type') == 'LOCATIONS':
                locs = data.get('locations') or []
                if not locs:
                    return []
                params2 = dict(params)
                params2['location'] = locs[0]
                try:
                    r = _do_get(params2)
                except requests.exceptions.SSLError:
                    if os.getenv("CJ_USE_OLD_HTTP") == "1":
                        return self._fallback_old_api(term, locs[0], locale_code, page, user_ip, user_agent, page_url)
                    return []
                if r.status_code != 200:
                    if os.getenv("CJ_USE_OLD_HTTP") == "1":
                        return self._fallback_old_api(term, locs[0], locale_code, page, user_ip, user_agent, page_url)
                    return []
                data = r.json() or {}

            if data.get('type') != 'JOBS':
                # –µ—Å–ª–∏ –Ω–æ–≤—ã–π API –Ω–µ –¥–∞—ë—Ç JOBS ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º —Å—Ç–∞—Ä—ã–π, –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–æ
                if os.getenv("CJ_USE_OLD_HTTP") == "1":
                    return self._fallback_old_api(term, location, locale_code, page, user_ip, user_agent, page_url)
                return []

            jobs_raw = data.get('jobs') or []
            batch: List[JobVacancy] = []
            for raw in jobs_raw:
                job = self._normalize_job_data(raw, country_name, term)
                if job:
                    batch.append(job)

            print(f"üìÑ Careerjet: {location} term='{term}' page {page}: +{len(batch)}")
            return batch

        except requests.Timeout:
            print(f"‚ö†Ô∏è Careerjet: —Ç–∞–π–º–∞—É—Ç page={page} [{location}] term='{term}'")
            return []
        except Exception as e:
            print(f"‚ùå Careerjet: –æ—à–∏–±–∫–∞ page={page} [{location}] term='{term}': {e}")
            return []



    def _fallback_old_api(self, term: str, location: str, locale_code: str, page: int,
                      user_ip: str, user_agent: str, page_url: str) -> List[JobVacancy]:
        """
        –í—Ä–µ–º–µ–Ω–Ω—ã–π –æ–±—Ö–æ–¥ –Ω–∞ —Å—Ç–∞—Ä—ã–π HTTP API (v3). –í–∫–ª—é—á–∞–µ—Ç—Å—è, –µ—Å–ª–∏ CJ_USE_OLD_HTTP=1.
        """
        try:
            old_url = "http://public.api.careerjet.net/search"
            old_params = {
                'affid': getattr(self, "affid", os.getenv('CAREERJET_AFFID', '')),
                'keywords': term,
                'location': location or '',
                'page': page,
                'pagesize': 20,
                'sort': 'date',
                'locale_code': locale_code,
                'user_ip': user_ip,
                'user_agent': user_agent,
                # Careerjet –ø—Ä–æ—Å–∏—Ç URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã-–∏—Å—Ç–æ—á–Ω–∏–∫–∞
                'url': page_url or os.getenv("CAREERJET_REFERER", "https://www.globaljobhunter.vip/results"),
            }
            r = self.session.get(old_url, params=old_params, timeout=15)
            if r.status_code != 200:
                return []
            data = r.json() or {}
            if data.get('type') != 'JOBS':
                return []
            jobs_raw = data.get('jobs') or []
            print(f"üü° TEMP fallback to old public.api.careerjet.net/search succeeded (+{len(jobs_raw)})")
            # country_name –Ω–∞–º —É–∂–µ –ø–µ—Ä–µ–¥–∞—é—Ç –≤ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥; —Ç—É—Ç –Ω–µ –≤—ã—á–∏—Å–ª—è–µ–º –∑–∞–Ω–æ–≤–æ
            # –≤–µ—Ä–Ω—ë–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–∞ –±–∞–∑–µ —Ç–æ–≥–æ –∂–µ —Ç–µ—Ä–º–∞
            out: List[JobVacancy] = []
            for raw in jobs_raw:
                job = self._normalize_job_data(raw, location, term)  # –ø–µ—Ä–µ–¥–∞—ë–º location –∫–∞–∫ country_name-–ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                if job:
                    out.append(job)
            return out
        except Exception as e:
            print(f"‚ùå Old API fallback failed: {e}")
            return []
        

    def _get_locale_code(self, country_code: str) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π locale_code –¥–ª—è Careerjet."""
        return self.locale_map.get(country_code.lower(), 'en_GB')
        


    # DEPRECATED: legacy Careerjet v3.0 flow ‚Äî not used with v4 API
    def _fetch_all_pages_legacy(
    self,
    keywords: str,
    location: str,
    country_code: str,
    progress_callback=None,
    cancel_check=None
) -> List[JobVacancy]:
        page = 1
        total_jobs: List[JobVacancy] = []

        while True:
            if cancel_check and cancel_check():
                break

            search_params = {
                'affid': self.affid,
                'keywords': keywords,
                'location': location,
                'page': page,
                'sort': 'date',
                'user_ip': '127.0.0.1',
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36'
            }
            cache_key_params = {k: v for k, v in search_params.items() if k not in ['user_ip', 'user_agent']}

            cached_result = self.cache_manager.get_cached_result(cache_key_params)
            if cached_result:
                total_jobs.extend(cached_result)
                if progress_callback and cached_result:
                    try:
                        progress_callback(cached_result)
                    except Exception:
                        pass
                if len(cached_result) < 50:
                    break
                page += 1
                continue

            self.rate_limiter.wait_if_needed(cancel_check=cancel_check)
            if cancel_check and cancel_check():
                return total_jobs

            try:
                response = requests.get(self.base_url, params=search_params, timeout=15)
                if response.status_code != 200:
                    print(f"‚ùå {self.source_name} API {response.status_code}: {response.text}")
                    break

                data = response.json()
                if data.get('type') == 'ERROR':
                    print(f"‚ùå {self.source_name} API error: {data.get('error')}")
                    break

                jobs_on_page_raw = data.get('jobs', [])
                if not jobs_on_page_raw:
                    break

                normalized_jobs: List[JobVacancy] = []
                country_name = self._get_country_name_by_code(country_code)
                for job_data in jobs_on_page_raw:
                    job = self._normalize_job_data(job_data, country_name, keywords)
                    if job:
                        normalized_jobs.append(job)

                total_jobs.extend(normalized_jobs)
                # ‚¨áÔ∏è –ö–ï–®–ò–†–£–ï–ú –¢–û–õ–¨–ö–û –ù–ï–ü–£–°–¢–´–ï –°–¢–†–ê–ù–ò–¶–´
                if normalized_jobs:
                    self.cache_manager.cache_result(cache_key_params, normalized_jobs)

                print(f"üìÑ {self.source_name}: {location} ‚Äî —Å—Ç—Ä. {page}, –Ω–∞–π–¥–µ–Ω–æ: {len(normalized_jobs)}")

                if progress_callback and normalized_jobs:
                    try:
                        progress_callback(normalized_jobs)
                    except Exception:
                        pass

                pagesize = data.get('pagesize') or len(jobs_on_page_raw)
                if len(jobs_on_page_raw) < pagesize:
                    break

                page += 1
                time.sleep(0.3)

            except requests.Timeout:
                print(f"‚ö†Ô∏è {self.source_name}: —Ç–∞–π–º–∞—É—Ç, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º –¥–ª—è '{location}'")
                break
            except Exception as e:
                print(f"‚ùå {self.source_name}: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
                break

        return total_jobs



    def _normalize_job_data(self, raw_job: Dict, country_name: str, search_term: str) -> Optional[JobVacancy]:
        """
        –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç API –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ–±—ä–µ–∫—Ç JobVacancy.
        """
        try:
            title = raw_job.get('title', '')
            description = raw_job.get('description', '')
            if not self.is_relevant_job(title, description, search_term):
                return None

            url = raw_job.get('url')
            if not url:
                return None
            job_id = hashlib.md5(url.encode()).hexdigest()

            date_str = raw_job.get('date', '')
            try:
                posted_date = datetime.strptime(date_str, '%a, %d %b %Y %H:%M:%S %Z').strftime('%Y-%m-%d')
            except (ValueError, TypeError):
                posted_date = datetime.now().strftime('%Y-%m-%d')

            return JobVacancy(
                id=f"careerjet_{job_id}",
                title=title,
                company=raw_job.get('company', 'Not specified'),
                location=raw_job.get('locations', 'Not specified'),
                salary=raw_job.get('salary'),
                description=description,
                apply_url=url,
                source=self.source_name,
                posted_date=posted_date,
                country=country_name,
                job_type=None,
                language_requirement=self.determine_language_requirement(title, description),
                refugee_friendly=self.is_refugee_friendly(title, description, search_term)
            )
        except Exception as e:
            print(f"‚ö†Ô∏è {self.source_name}: –û—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
            return None

    def is_relevant_job(self, job_title: str, job_description: str, search_term: str) -> bool:
        """
        –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å.
        """
        search_terms = search_term.lower().split()
        title_lower = job_title.lower()
        
        return any(term in title_lower for term in search_terms if len(term) > 2)

    def _get_country_name_by_code(self, country_code: str) -> str:
        """
        –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ –∏–º–µ–Ω–∏ —Å—Ç—Ä–∞–Ω—ã –ø–æ –∫–æ–¥—É.
        """
        return self.adzuna_countries.get(country_code, {}).get('name', country_code.upper())

    def _deduplicate_jobs(self, jobs: List[JobVacancy]) -> List[JobVacancy]:
        """–£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ–º—É –∫–ª—é—á—É."""
        seen = set()
        unique_jobs = []
        for job in jobs:
            if job.apply_url not in seen:
                seen.add(job.apply_url)
                unique_jobs.append(job)
        return unique_jobs

if __name__ == '__main__':
    print("üöÄ –¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫ CareerjetAggregator...")
    
    try:
        main_aggregator_for_test = GlobalJobAggregator()
        aggregator = CareerjetAggregator(
            adzuna_countries=main_aggregator_for_test.countries,
            specific_jobs_map=main_aggregator_for_test.specific_jobs
        )
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∞: {e}")
        aggregator = None

    if aggregator:
        test_preferences = {
            'selected_jobs': ['–ó–∞–ø—Ä–∞–≤—â–∏–∫ –Ω–∞ –ê–ó–°', '–û–ø–µ—Ä–∞—Ç–æ—Ä –ê–ó–°'],
            'countries': ['us'],
            'cities': [] # <-- –¢–µ—Å—Ç–∏—Ä—É–µ–º –±–µ–∑ –≥–æ—Ä–æ–¥–∞
        }
        
        start_time = time.time()
        found_jobs = aggregator.search_jobs(test_preferences)
        end_time = time.time()
        
        print(f"\n\n--- –†–ï–ó–£–õ–¨–¢–ê–¢–´ –¢–ï–°–¢–ê ---")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {end_time - start_time:.2f} —Å–µ–∫—É–Ω–¥")
        print(f"üìä –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(found_jobs)}")
        
        if found_jobs:
            print("\nüìù –ü—Ä–∏–º–µ—Ä 5 –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π:")
            for i, job in enumerate(found_jobs[:5]):
                print(f"  {i+1}. {job.title} –≤ {job.company} ({job.location})")
                print(f"     –°—Å—ã–ª–∫–∞: {job.apply_url}")
